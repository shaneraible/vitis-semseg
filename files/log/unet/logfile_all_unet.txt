/**

* Â© Copyright (C) 2016-2020 Xilinx, Inc
*
* Licensed under the Apache License, Version 2.0 (the "License"). You may
* not use this file except in compliance with the License. A copy of the
* License is located at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
* WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
* License for the specific language governing permissions and limitations
* under the License.
*/



 
##################################################################################
Step2a: TRAINING
##################################################################################
 
2020-03-05 09:51:45.740355: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 09:51:45.832462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 09:51:45.832483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 09:51:46.358721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 09:51:46.358742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 09:51:46.358746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 09:51:46.359369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20768 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
UNET MODEL =  1
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 224, 224, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 224, 224, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 224, 224, 64) 256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 224, 224, 64) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 224, 224, 64) 36928       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 224, 224, 64) 256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 224, 224, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64) 0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 112, 112, 64) 0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 112, 112, 128 73856       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 112, 112, 128 512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 112, 112, 128 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 112, 112, 128 147584      activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 112, 112, 128 512         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 112, 112, 128 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 128)  0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 56, 56, 128)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 56, 56, 256)  295168      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 56, 56, 256)  1024        conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 56, 56, 256)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 56, 56, 256)  590080      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 56, 56, 256)  1024        conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 56, 256)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 28, 28, 256)  0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 512)  1180160     dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 512)  2048        conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 512)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 512)  2359808     activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 512)  2048        conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 512)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 14, 14, 512)  0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 14, 1024) 4719616     dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 14, 1024) 4096        conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 14, 1024) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 14, 1024) 9438208     activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 14, 1024) 4096        conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 14, 1024) 0           activation_10[0][0]              2020-03-05 09:51:57.770357: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.45GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-03-05 09:51:58.228653: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.02GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-03-05 09:51:58.809470: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.45GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 1024) 0           dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 28, 1536) 0           up_sampling2d_1[0][0]            
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 28, 1536) 0           concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 512)  7078400     dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 28, 512)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 512)  2359808     activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 28, 512)  2048        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 28, 512)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 512)  0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 56, 56, 768)  0           up_sampling2d_2[0][0]            
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 56, 768)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 56, 256)  1769728     dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 56, 256)  1024        conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 56, 256)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 56, 256)  590080      activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 56, 256)  1024        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 56, 256)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 256 0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 112, 112, 384 0           up_sampling2d_3[0][0]            
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 112, 112, 384 0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 112, 112, 128 442496      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 112, 112, 128 512         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 112, 112, 128 0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 112, 112, 128 147584      activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 112, 112, 128 512         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 112, 112, 128 0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 128 0           activation_16[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 224, 224, 192 0           up_sampling2d_4[0][0]            
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 224, 224, 192 0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 224, 224, 64) 110656      dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 224, 224, 64) 256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 224, 224, 64) 0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 224, 224, 64) 36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 224, 224, 64) 256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 224, 224, 64) 0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 224, 224, 12) 6924        activation_18[0][0]              
==================================================================================================
Total params: 31,409,356
Trainable params: 31,397,580
Non-trainable params: 11,776
__________________________________________________________________________________________________
(311, 224, 224, 3) (311, 224, 224, 12)
(56, 224, 224, 3) (56, 224, 224, 12)
Train on 311 samples, validate on 56 samples
Epoch 1/200
 - 24s - loss: 2.7247 - acc: 0.4203 - val_loss: 1.9894 - val_acc: 0.3172
Epoch 2/200
 - 11s - loss: 1.6301 - acc: 0.4584 - val_loss: 1.7900 - val_acc: 0.3897
Epoch 3/200
 - 11s - loss: 1.5163 - acc: 0.4718 - val_loss: 1.6677 - val_acc: 0.4364
Epoch 4/200
 - 12s - loss: 1.4139 - acc: 0.5135 - val_loss: 1.6686 - val_acc: 0.4974
Epoch 5/200
 - 12s - loss: 1.3197 - acc: 0.5874 - val_loss: 1.6725 - val_acc: 0.5384
Epoch 6/200
 - 12s - loss: 1.2609 - acc: 0.6340 - val_loss: 1.8125 - val_acc: 0.5356
Epoch 7/200
 - 12s - loss: 1.2008 - acc: 0.6545 - val_loss: 1.6542 - val_acc: 0.5757
Epoch 8/200
 - 12s - loss: 1.1340 - acc: 0.6669 - val_loss: 2.0504 - val_acc: 0.5880
Epoch 9/200
 - 12s - loss: 1.0782 - acc: 0.6748 - val_loss: 2.1126 - val_acc: 0.5941
Epoch 10/200
 - 12s - loss: 1.0215 - acc: 0.6797 - val_loss: 1.9751 - val_acc: 0.6128
Epoch 11/200
 - 12s - loss: 0.9936 - acc: 0.6816 - val_loss: 1.9440 - val_acc: 0.6179
Epoch 12/200
 - 12s - loss: 0.9825 - acc: 0.6807 - val_loss: 1.2413 - val_acc: 0.6279
Epoch 13/200
 - 12s - loss: 0.9631 - acc: 0.6833 - val_loss: 1.2764 - val_acc: 0.6368
Epoch 14/200
 - 12s - loss: 0.9467 - acc: 0.6839 - val_loss: 1.1783 - val_acc: 0.6558
Epoch 15/200
 - 12s - loss: 0.9353 - acc: 0.6850 - val_loss: 2.1581 - val_acc: 0.6081
Epoch 16/200
 - 12s - loss: 0.9159 - acc: 0.6872 - val_loss: 1.6748 - val_acc: 0.6325
Epoch 17/200
 - 12s - loss: 0.8958 - acc: 0.6882 - val_loss: 2.0145 - val_acc: 0.6138
Epoch 18/200
 - 12s - loss: 0.8954 - acc: 0.6888 - val_loss: 2.2939 - val_acc: 0.6091
Epoch 19/200
 - 12s - loss: 0.8755 - acc: 0.6896 - val_loss: 2.2115 - val_acc: 0.6206
Epoch 20/200
 - 12s - loss: 0.8511 - acc: 0.6907 - val_loss: 1.8521 - val_acc: 0.6337
Epoch 21/200
 - 12s - loss: 0.8517 - acc: 0.6922 - val_loss: 1.4116 - val_acc: 0.6568
Epoch 22/200
 - 12s - loss: 0.8265 - acc: 0.6962 - val_loss: 1.4119 - val_acc: 0.6605
Epoch 23/200
 - 12s - loss: 0.8149 - acc: 0.7007 - val_loss: 1.3843 - val_acc: 0.6610
Epoch 24/200
 - 12s - loss: 0.8184 - acc: 0.7028 - val_loss: 1.3435 - val_acc: 0.6722
Epoch 25/200
 - 12s - loss: 0.8168 - acc: 0.7135 - val_loss: 1.1420 - val_acc: 0.6871
Epoch 26/200
 - 12s - loss: 0.7957 - acc: 0.7260 - val_loss: 1.1978 - val_acc: 0.6837
Epoch 27/200
 - 12s - loss: 0.7902 - acc: 0.7340 - val_loss: 1.4165 - val_acc: 0.6839
Epoch 28/200
 - 12s - loss: 0.7962 - acc: 0.7355 - val_loss: 1.6121 - val_acc: 0.6869
Epoch 29/200
 - 12s - loss: 0.7675 - acc: 0.7487 - val_loss: 1.5326 - val_acc: 0.6875
Epoch 30/200
 - 12s - loss: 0.7533 - acc: 0.7659 - val_loss: 1.3395 - val_acc: 0.6528
Epoch 31/200
 - 12s - loss: 0.7538 - acc: 0.7759 - val_loss: 1.2441 - val_acc: 0.6948
Epoch 32/200
 - 12s - loss: 0.7442 - acc: 0.7822 - val_loss: 1.1741 - val_acc: 0.6935
Epoch 33/200
 - 12s - loss: 0.7127 - acc: 0.7983 - val_loss: 1.3483 - val_acc: 0.6951
Epoch 34/200
 - 12s - loss: 0.7315 - acc: 0.7947 - val_loss: 1.3240 - val_acc: 0.7001
Epoch 35/200
 - 12s - loss: 0.7441 - acc: 0.7897 - val_loss: 1.1067 - val_acc: 0.7145
Epoch 36/200
 - 12s - loss: 0.7391 - acc: 0.7888 - val_loss: 1.3752 - val_acc: 0.7004
Epoch 37/200
 - 12s - loss: 0.7110 - acc: 0.8023 - val_loss: 1.2889 - val_acc: 0.7136
Epoch 38/200
 - 12s - loss: 0.6915 - acc: 0.8078 - val_loss: 1.3506 - val_acc: 0.7178
Epoch 39/200
 - 12s - loss: 0.6776 - acc: 0.8148 - val_loss: 1.3313 - val_acc: 0.7137
Epoch 40/200
 - 12s - loss: 0.6661 - acc: 0.8163 - val_loss: 1.3001 - val_acc: 0.7180
Epoch 41/200
 - 12s - loss: 0.6692 - acc: 0.8157 - val_loss: 1.3018 - val_acc: 0.7147
Epoch 42/200
 - 12s - loss: 0.6636 - acc: 0.8185 - val_loss: 1.1503 - val_acc: 0.7225
Epoch 43/200
 - 12s - loss: 0.6590 - acc: 0.8180 - val_loss: 1.0114 - val_acc: 0.7358
Epoch 44/200
 - 12s - loss: 0.6412 - acc: 0.8258 - val_loss: 1.3664 - val_acc: 0.7101
Epoch 45/200
 - 12s - loss: 0.7301 - acc: 0.8012 - val_loss: 1.0433 - val_acc: 0.7211
Epoch 46/200
 - 12s - loss: 0.7626 - acc: 0.7819 - val_loss: 1.2110 - val_acc: 0.6535
Epoch 47/200
 - 12s - loss: 0.8212 - acc: 0.7710 - val_loss: 1.1510 - val_acc: 0.7145
Epoch 48/200
 - 12s - loss: 0.7371 - acc: 0.8015 - val_loss: 1.2051 - val_acc: 0.7133
Epoch 49/200
 - 12s - loss: 0.7012 - acc: 0.8094 - val_loss: 1.1245 - val_acc: 0.7221
Epoch 50/200
 - 12s - loss: 0.7237 - acc: 0.8027 - val_loss: 1.3378 - val_acc: 0.7192
Epoch 51/200
 - 12s - loss: 0.6895 - acc: 0.8122 - val_loss: 1.0636 - val_acc: 0.7352
Epoch 52/200
 - 12s - loss: 0.6631 - acc: 0.8169 - val_loss: 1.1073 - val_acc: 0.7399
Epoch 53/200
 - 12s - loss: 0.6362 - acc: 0.8256 - val_loss: 1.3457 - val_acc: 0.6914
Epoch 54/200
 - 12s - loss: 0.6272 - acc: 0.8272 - val_loss: 1.1748 - val_acc: 0.7288
Epoch 55/200
 - 12s - loss: 0.6261 - acc: 0.8266 - val_loss: 1.1044 - val_acc: 0.7303
Epoch 56/200
 - 12s - loss: 0.6109 - acc: 0.8310 - val_loss: 1.0676 - val_acc: 0.7284
Epoch 57/200
 - 12s - loss: 0.5993 - acc: 0.8323 - val_loss: 1.0150 - val_acc: 0.7419
Epoch 58/200
 - 12s - loss: 0.6052 - acc: 0.8336 - val_loss: 0.9048 - val_acc: 0.7551
Epoch 59/200
 - 12s - loss: 0.6021 - acc: 0.8334 - val_loss: 1.0878 - val_acc: 0.7155
Epoch 60/200
 - 12s - loss: 0.5969 - acc: 0.8348 - val_loss: 0.9892 - val_acc: 0.7505
Epoch 61/200
 - 12s - loss: 0.5994 - acc: 0.8326 - val_loss: 0.8426 - val_acc: 0.7624
Epoch 62/200
 - 12s - loss: 0.6144 - acc: 0.8267 - val_loss: 0.9236 - val_acc: 0.7476
Epoch 63/200
 - 12s - loss: 0.5898 - acc: 0.8332 - val_loss: 1.1672 - val_acc: 0.7189
Epoch 64/200
 - 12s - loss: 0.5931 - acc: 0.8330 - val_loss: 1.1025 - val_acc: 0.7423
Epoch 65/200
 - 12s - loss: 0.5847 - acc: 0.8353 - val_loss: 1.0113 - val_acc: 0.7505
Epoch 66/200
 - 12s - loss: 0.5806 - acc: 0.8357 - val_loss: 0.8329 - val_acc: 0.7727
Epoch 67/200
 - 12s - loss: 0.5833 - acc: 0.8338 - val_loss: 0.9976 - val_acc: 0.7435
Epoch 68/200
 - 12s - loss: 0.5718 - acc: 0.8378 - val_loss: 0.9120 - val_acc: 0.7647
Epoch 69/200
 - 12s - loss: 0.5526 - acc: 0.8434 - val_loss: 1.0182 - val_acc: 0.7487
Epoch 70/200
 - 12s - loss: 0.5476 - acc: 0.8434 - val_loss: 0.8507 - val_acc: 0.7715
Epoch 71/200
 - 12s - loss: 0.5499 - acc: 0.8448 - val_loss: 0.8949 - val_acc: 0.7830
Epoch 72/200
 - 12s - loss: 0.5582 - acc: 0.8433 - val_loss: 0.9120 - val_acc: 0.7720
Epoch 73/200
 - 12s - loss: 0.5488 - acc: 0.8446 - val_loss: 0.9810 - val_acc: 0.7615
Epoch 74/200
 - 12s - loss: 0.5572 - acc: 0.8431 - val_loss: 1.1013 - val_acc: 0.7456
Epoch 75/200
 - 12s - loss: 0.5544 - acc: 0.8430 - val_loss: 0.7677 - val_acc: 0.7995
Epoch 76/200
 - 12s - loss: 0.5388 - acc: 0.8462 - val_loss: 0.7474 - val_acc: 0.8037
Epoch 77/200
 - 12s - loss: 0.5291 - acc: 0.8478 - val_loss: 0.8010 - val_acc: 0.7830
Epoch 78/200
 - 12s - loss: 0.5273 - acc: 0.8485 - val_loss: 0.7847 - val_acc: 0.8040
Epoch 79/200
 - 12s - loss: 0.5244 - acc: 0.8492 - val_loss: 0.7236 - val_acc: 0.8073
Epoch 80/200
 - 12s - loss: 0.5324 - acc: 0.8468 - val_loss: 0.7758 - val_acc: 0.7926
Epoch 81/200
 - 12s - loss: 0.6366 - acc: 0.8191 - val_loss: 2.3804 - val_acc: 0.6068
Epoch 82/200
 - 12s - loss: 0.5984 - acc: 0.8328 - val_loss: 2.1717 - val_acc: 0.6332
Epoch 83/200
 - 12s - loss: 0.5714 - acc: 0.8389 - val_loss: 2.0052 - val_acc: 0.6688
Epoch 84/200
 - 12s - loss: 0.5461 - acc: 0.8434 - val_loss: 1.6995 - val_acc: 0.6973
Epoch 85/200
 - 12s - loss: 0.5523 - acc: 0.8405 - val_loss: 1.1887 - val_acc: 0.7439
Epoch 86/200
 - 12s - loss: 0.5662 - acc: 0.8404 - val_loss: 1.0762 - val_acc: 0.7528
Epoch 87/200
 - 12s - loss: 0.5493 - acc: 0.8447 - val_loss: 0.8886 - val_acc: 0.7753
Epoch 88/200
 - 12s - loss: 0.5395 - acc: 0.8456 - val_loss: 0.8708 - val_acc: 0.7637
Epoch 89/200
 - 12s - loss: 0.5349 - acc: 0.8468 - val_loss: 0.8711 - val_acc: 0.7736
Epoch 90/200
 - 12s - loss: 0.5333 - acc: 0.8471 - val_loss: 0.9498 - val_acc: 0.7675
Epoch 91/200
 - 12s - loss: 0.5210 - acc: 0.8497 - val_loss: 0.9350 - val_acc: 0.7761
Epoch 92/200
 - 12s - loss: 0.5185 - acc: 0.8510 - val_loss: 0.8856 - val_acc: 0.7665
Epoch 93/200
 - 12s - loss: 0.5037 - acc: 0.8539 - val_loss: 0.9107 - val_acc: 0.7526
Epoch 94/200
 - 12s - loss: 0.5110 - acc: 0.8519 - val_loss: 0.8814 - val_acc: 0.7522
Epoch 95/200
 - 12s - loss: 0.5056 - acc: 0.8554 - val_loss: 0.8036 - val_acc: 0.7739
Epoch 96/200
 - 12s - loss: 0.5067 - acc: 0.8538 - val_loss: 0.8039 - val_acc: 0.7653
Epoch 97/200
 - 12s - loss: 0.5326 - acc: 0.8512 - val_loss: 1.4353 - val_acc: 0.6574
Epoch 98/200
 - 12s - loss: 0.6070 - acc: 0.8282 - val_loss: 0.9550 - val_acc: 0.7374
Epoch 99/200
 - 12s - loss: 0.5658 - acc: 0.8431 - val_loss: 0.8874 - val_acc: 0.7669
Epoch 100/200
 - 12s - loss: 0.5376 - acc: 0.8507 - val_loss: 0.8496 - val_acc: 0.7945
Epoch 101/200
 - 12s - loss: 0.5257 - acc: 0.8524 - val_loss: 0.8932 - val_acc: 0.7909
Epoch 102/200
 - 12s - loss: 0.5328 - acc: 0.8536 - val_loss: 0.7861 - val_acc: 0.8154
Epoch 103/200
 - 12s - loss: 0.5319 - acc: 0.8545 - val_loss: 0.7943 - val_acc: 0.7938
Epoch 104/200
 - 12s - loss: 0.5108 - acc: 0.8567 - val_loss: 0.7444 - val_acc: 0.8030
Epoch 105/200
 - 12s - loss: 0.5614 - acc: 0.8420 - val_loss: 0.8217 - val_acc: 0.7933
Epoch 106/200
 - 12s - loss: 0.5372 - acc: 0.8513 - val_loss: 0.7284 - val_acc: 0.8025
Epoch 107/200
 - 12s - loss: 0.5228 - acc: 0.8556 - val_loss: 0.7426 - val_acc: 0.8051
Epoch 108/200
 - 12s - loss: 0.5104 - acc: 0.8589 - val_loss: 0.7259 - val_acc: 0.7962
Epoch 109/200
 - 12s - loss: 0.5032 - acc: 0.8599 - val_loss: 0.7314 - val_acc: 0.7975
Epoch 110/200
 - 12s - loss: 0.4928 - acc: 0.8612 - val_loss: 0.7282 - val_acc: 0.8091
Epoch 111/200
 - 12s - loss: 0.4858 - acc: 0.8633 - val_loss: 0.7659 - val_acc: 0.7960
Epoch 112/200
 - 12s - loss: 0.4864 - acc: 0.8634 - val_loss: 0.6871 - val_acc: 0.8128
Epoch 113/200
 - 12s - loss: 0.4814 - acc: 0.8644 - val_loss: 0.7767 - val_acc: 0.7938
Epoch 114/200
 - 12s - loss: 0.4762 - acc: 0.8659 - val_loss: 0.7392 - val_acc: 0.7944
Epoch 115/200
 - 12s - loss: 0.4905 - acc: 0.8607 - val_loss: 0.7451 - val_acc: 0.8029
Epoch 116/200
 - 12s - loss: 0.4778 - acc: 0.8656 - val_loss: 0.7564 - val_acc: 0.8041
Epoch 117/200
 - 12s - loss: 0.4772 - acc: 0.8672 - val_loss: 0.6340 - val_acc: 0.8244
Epoch 118/200
 - 12s - loss: 0.4730 - acc: 0.8673 - val_loss: 0.6528 - val_acc: 0.8202
Epoch 119/200
 - 12s - loss: 0.4683 - acc: 0.8684 - val_loss: 0.6424 - val_acc: 0.8196
Epoch 120/200
 - 12s - loss: 0.4715 - acc: 0.8671 - val_loss: 0.6560 - val_acc: 0.8180
Epoch 121/200
 - 12s - loss: 0.4661 - acc: 0.8698 - val_loss: 0.6816 - val_acc: 0.8099
Epoch 122/200
 - 12s - loss: 0.4636 - acc: 0.8698 - val_loss: 0.7004 - val_acc: 0.8070
Epoch 123/200
 - 12s - loss: 0.4595 - acc: 0.8710 - val_loss: 0.6890 - val_acc: 0.8112
Epoch 124/200
 - 12s - loss: 0.4718 - acc: 0.8670 - val_loss: 0.6525 - val_acc: 0.8200
Epoch 125/200
 - 12s - loss: 0.4766 - acc: 0.8659 - val_loss: 0.8749 - val_acc: 0.8093
Epoch 126/200
 - 12s - loss: 0.5016 - acc: 0.8612 - val_loss: 0.7432 - val_acc: 0.8068
Epoch 127/200
 - 12s - loss: 0.4802 - acc: 0.8669 - val_loss: 0.7294 - val_acc: 0.8150
Epoch 128/200
 - 12s - loss: 0.4793 - acc: 0.8655 - val_loss: 0.7616 - val_acc: 0.8075
Epoch 129/200
 - 12s - loss: 0.4739 - acc: 0.8670 - val_loss: 0.6993 - val_acc: 0.8122
Epoch 130/200
 - 12s - loss: 0.4643 - acc: 0.8700 - val_loss: 0.6613 - val_acc: 0.8193
Epoch 131/200
 - 12s - loss: 0.4643 - acc: 0.8694 - val_loss: 0.6432 - val_acc: 0.8268
Epoch 132/200
 - 12s - loss: 0.4589 - acc: 0.8709 - val_loss: 0.6957 - val_acc: 0.8150
Epoch 133/200
 - 12s - loss: 0.4573 - acc: 0.8722 - val_loss: 0.6521 - val_acc: 0.8215
Epoch 134/200
 - 12s - loss: 0.4611 - acc: 0.8726 - val_loss: 0.6603 - val_acc: 0.8193
Epoch 135/200
 - 12s - loss: 0.4543 - acc: 0.8730 - val_loss: 0.6952 - val_acc: 0.8120
Epoch 136/200
 - 12s - loss: 0.4470 - acc: 0.8743 - val_loss: 0.6655 - val_acc: 0.8190
Epoch 137/200
 - 12s - loss: 0.4480 - acc: 0.8740 - val_loss: 0.7560 - val_acc: 0.7874
Epoch 138/200
 - 12s - loss: 0.4502 - acc: 0.8744 - val_loss: 0.7459 - val_acc: 0.7941
Epoch 139/200
 - 12s - loss: 0.4509 - acc: 0.8736 - val_loss: 0.7543 - val_acc: 0.7981
Epoch 140/200
 - 12s - loss: 0.4510 - acc: 0.8742 - val_loss: 0.6836 - val_acc: 0.8121
Epoch 141/200
 - 12s - loss: 0.4479 - acc: 0.8741 - val_loss: 0.6615 - val_acc: 0.8163
Epoch 142/200
 - 12s - loss: 0.4454 - acc: 0.8745 - val_loss: 0.6716 - val_acc: 0.8208
Epoch 143/200
 - 12s - loss: 0.4518 - acc: 0.8726 - val_loss: 0.7282 - val_acc: 0.8162
Epoch 144/200
 - 12s - loss: 0.4625 - acc: 0.8701 - val_loss: 0.7360 - val_acc: 0.8050
Epoch 145/200
 - 12s - loss: 0.4537 - acc: 0.8729 - val_loss: 0.6375 - val_acc: 0.8224
Epoch 146/200
 - 12s - loss: 0.4499 - acc: 0.8735 - val_loss: 0.9863 - val_acc: 0.7621
Epoch 147/200
 - 12s - loss: 0.4459 - acc: 0.8754 - val_loss: 0.6915 - val_acc: 0.8185
Epoch 148/200
 - 12s - loss: 0.4394 - acc: 0.8771 - val_loss: 0.6893 - val_acc: 0.8164
Epoch 149/200
 - 12s - loss: 0.4429 - acc: 0.8761 - val_loss: 0.6788 - val_acc: 0.8140
Epoch 150/200
 - 12s - loss: 0.4417 - acc: 0.8757 - val_loss: 0.7075 - val_acc: 0.8092
Epoch 151/200
 - 12s - loss: 0.4455 - acc: 0.8753 - val_loss: 0.6935 - val_acc: 0.8122
Epoch 152/200
 - 12s - loss: 0.4442 - acc: 0.8756 - val_loss: 0.6778 - val_acc: 0.8132
Epoch 153/200
 - 12s - loss: 0.4397 - acc: 0.8774 - val_loss: 0.6784 - val_acc: 0.8214
Epoch 154/200
 - 12s - loss: 0.4359 - acc: 0.8776 - val_loss: 0.6834 - val_acc: 0.8177
Epoch 155/200
 - 12s - loss: 0.4328 - acc: 0.8783 - val_loss: 0.6895 - val_acc: 0.8168
Epoch 156/200
 - 12s - loss: 0.4377 - acc: 0.8766 - val_loss: 0.6694 - val_acc: 0.8221
Epoch 157/200
 - 12s - loss: 0.4357 - acc: 0.8775 - val_loss: 0.6435 - val_acc: 0.8248
Epoch 158/200
 - 12s - loss: 0.4371 - acc: 0.8779 - val_loss: 0.7030 - val_acc: 0.8079
Epoch 159/200
 - 12s - loss: 0.4343 - acc: 0.8780 - val_loss: 0.7238 - val_acc: 0.8092
Epoch 160/200
 - 12s - loss: 0.4381 - acc: 0.8782 - val_loss: 0.6882 - val_acc: 0.8210
Epoch 161/200
 - 12s - loss: 0.4417 - acc: 0.8761 - val_loss: 0.7490 - val_acc: 0.8096
Epoch 162/200
 - 12s - loss: 0.4355 - acc: 0.8784 - val_loss: 0.7058 - val_acc: 0.8151
Epoch 163/200
 - 12s - loss: 0.4314 - acc: 0.8788 - val_loss: 0.7458 - val_acc: 0.8083
Epoch 164/200
 - 12s - loss: 0.4319 - acc: 0.8785 - val_loss: 0.6707 - val_acc: 0.8232
Epoch 165/200
 - 12s - loss: 0.4310 - acc: 0.8792 - val_loss: 0.7134 - val_acc: 0.8119
Epoch 166/200
 - 12s - loss: 0.4262 - acc: 0.8802 - val_loss: 0.7528 - val_acc: 0.8048
Epoch 167/200
 - 12s - loss: 0.4318 - acc: 0.8801 - val_loss: 0.7336 - val_acc: 0.8067
Epoch 168/200
 - 12s - loss: 0.4267 - acc: 0.8812 - val_loss: 0.6907 - val_acc: 0.8183
Epoch 169/200
 - 12s - loss: 0.4301 - acc: 0.8798 - val_loss: 0.7040 - val_acc: 0.8166
Epoch 170/200
 - 12s - loss: 0.4277 - acc: 0.8799 - val_loss: 0.7065 - val_acc: 0.8146
Epoch 171/200
 - 12s - loss: 0.4244 - acc: 0.8800 - val_loss: 0.7747 - val_acc: 0.8039
Epoch 172/200
 - 12s - loss: 0.4370 - acc: 0.8776 - val_loss: 0.6554 - val_acc: 0.8231
Epoch 173/200
 - 12s - loss: 0.4415 - acc: 0.8777 - val_loss: 0.6593 - val_acc: 0.8246
Epoch 174/200
 - 12s - loss: 0.4338 - acc: 0.8799 - val_loss: 0.6261 - val_acc: 0.8312
Epoch 175/200
 - 12s - loss: 0.4285 - acc: 0.8808 - val_loss: 0.6459 - val_acc: 0.8257
Epoch 176/200
 - 12s - loss: 0.4304 - acc: 0.8790 - val_loss: 0.7302 - val_acc: 0.8075
Epoch 177/200
 - 12s - loss: 0.4389 - acc: 0.8786 - val_loss: 0.6143 - val_acc: 0.8351
Epoch 178/200
 - 12s - loss: 0.4334 - acc: 0.8801 - val_loss: 0.6310 - val_acc: 0.8345
Epoch 179/200
 - 12s - loss: 0.4343 - acc: 0.8789 - val_loss: 0.6830 - val_acc: 0.8175
Epoch 180/200
 - 12s - loss: 0.4336 - acc: 0.8791 - val_loss: 0.6774 - val_acc: 0.8213
Epoch 181/200
 - 12s - loss: 0.4256 - acc: 0.8809 - val_loss: 0.6271 - val_acc: 0.8318
Epoch 182/200
 - 12s - loss: 0.4272 - acc: 0.8800 - val_loss: 0.6537 - val_acc: 0.8222
Epoch 183/200
 - 12s - loss: 0.4263 - acc: 0.8797 - val_loss: 0.6935 - val_acc: 0.8144
Epoch 184/200
 - 12s - loss: 0.4279 - acc: 0.8797 - val_loss: 0.6310 - val_acc: 0.8315
Epoch 185/200
 - 12s - loss: 0.4271 - acc: 0.8800 - val_loss: 0.7862 - val_acc: 0.8106
Epoch 186/200
 - 12s - loss: 0.4163 - acc: 0.8827 - val_loss: 0.7642 - val_acc: 0.8163
Epoch 187/200
 - 12s - loss: 0.4183 - acc: 0.8814 - val_loss: 0.6786 - val_acc: 0.8259
Epoch 188/200
 - 12s - loss: 0.4164 - acc: 0.8823 - val_loss: 0.7150 - val_acc: 0.8239
Epoch 189/200
 - 12s - loss: 0.4214 - acc: 0.8805 - val_loss: 0.7474 - val_acc: 0.8149
Epoch 190/200
 - 12s - loss: 0.4211 - acc: 0.8819 - val_loss: 0.6863 - val_acc: 0.8278
Epoch 191/200
 - 12s - loss: 0.4196 - acc: 0.8827 - val_loss: 0.7035 - val_acc: 0.8182
Epoch 192/200
 - 12s - loss: 0.4440 - acc: 0.8760 - val_loss: 0.6381 - val_acc: 0.8292
Epoch 193/200
 - 12s - loss: 0.4574 - acc: 0.8738 - val_loss: 0.6561 - val_acc: 0.8278
Epoch 194/200
 - 12s - loss: 0.4385 - acc: 0.8787 - val_loss: 0.6290 - val_acc: 0.8305
Epoch 195/200
 - 12s - loss: 0.4271 - acc: 0.8812 - val_loss: 0.6279 - val_acc: 0.8327
Epoch 196/200
 - 12s - loss: 0.4245 - acc: 0.8821 - val_loss: 0.6799 - val_acc: 0.8299
Epoch 197/200
 - 12s - loss: 0.4230 - acc: 0.8818 - val_loss: 0.6573 - val_acc: 0.8340
Epoch 198/200
 - 12s - loss: 0.4207 - acc: 0.8824 - val_loss: 0.6446 - val_acc: 0.8282
Epoch 199/200
 - 12s - loss: 0.4201 - acc: 0.8829 - val_loss: 0.6178 - val_acc: 0.8317
Epoch 200/200
 - 12s - loss: 0.4186 - acc: 0.8834 - val_loss: 0.6302 - val_acc: 0.8332
Using TensorFlow backend.


Elapsed time for Keras training (s):  2336.640047



End of UNET training

2020-03-05 10:30:51.580052: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 10:30:51.661331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 10:30:51.661352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 10:30:52.167074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 10:30:52.167095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 10:30:52.167099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 10:30:52.167710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20768 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
UNET MODEL =  2
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 224, 224, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 224, 224, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 224, 224, 64) 256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 224, 224, 64) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 224, 224, 64) 36928       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 224, 224, 64) 256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 224, 224, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64) 0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 112, 112, 64) 0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 112, 112, 128 73856       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 112, 112, 128 512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 112, 112, 128 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 112, 112, 128 147584      activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 112, 112, 128 512         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 112, 112, 128 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 128)  0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 56, 56, 128)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 56, 56, 256)  295168      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 56, 56, 256)  1024        conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 56, 56, 256)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 56, 56, 256)  590080      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 56, 56, 256)  1024        conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 56, 256)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 28, 28, 256)  0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 512)  1180160     dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 512)  2048        conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 512)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 512)  2359808     activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 512)  2048        conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 512)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 14, 14, 512)  0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 14, 1024) 4719616     dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 14, 1024) 4096        conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 14, 1024) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 14, 1024) 9438208     activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 14, 1024) 4096        conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 14, 1024) 0           activation_10[0][0]              
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 1024) 0           dropout_5[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 512)  2097664     up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 28, 1024) 0           conv2d_11[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 28, 1024) 0           concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 512)  4719104     dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 28, 512)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 28, 28, 512)  2359808     activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 28, 512)  2048        conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 28, 512)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 512)  0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 56, 256)  524544      up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 56, 56, 512)  0           conv2d_14[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 56, 512)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 56, 256)  1179904     dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 56, 256)  1024        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 56, 256)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 56, 56, 256)  590080      activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 56, 256)  1024        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 56, 256)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 256 0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 112, 112, 128 131200      up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 112, 112, 256 0           conv2d_17[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 112, 112, 256 0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 112, 112, 128 295040      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 112, 112, 128 512         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 112, 112, 128 0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 112, 112, 128 147584      activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 112, 112, 128 512         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 112, 112, 128 0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 128 0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 224, 224, 64) 32832       up_sampling2d_4[0][0]            
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 224, 224, 128 0           conv2d_20[0][0]                  
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 224, 224, 128 0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 224, 224, 64) 73792       dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 224, 224, 64) 256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 224, 224, 64) 0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 224, 224, 64) 36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 224, 224, 64) 256         conv2d_22[0][0]                  
__________________________________________________________________________________________________2020-03-05 10:31:04.175631: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.45GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-03-05 10:31:04.641126: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.02GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

activation_18 (Activation)      (None, 224, 224, 64) 0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 224, 224, 12) 6924        activation_18[0][0]              
==================================================================================================
Total params: 31,062,156
Trainable params: 31,050,380
Non-trainable params: 11,776
__________________________________________________________________________________________________
(311, 224, 224, 3) (311, 224, 224, 12)
(56, 224, 224, 3) (56, 224, 224, 12)
Train on 311 samples, validate on 56 samples
Epoch 1/200
 - 25s - loss: 2.7406 - acc: 0.4369 - val_loss: 1.8630 - val_acc: 0.4328
Epoch 2/200
 - 12s - loss: 1.6735 - acc: 0.4830 - val_loss: 1.8008 - val_acc: 0.4311
Epoch 3/200
 - 12s - loss: 1.5770 - acc: 0.4957 - val_loss: 1.6446 - val_acc: 0.4564
Epoch 4/200
 - 12s - loss: 1.4855 - acc: 0.5096 - val_loss: 1.5140 - val_acc: 0.5126
Epoch 5/200
 - 12s - loss: 1.4056 - acc: 0.5249 - val_loss: 1.4345 - val_acc: 0.5363
Epoch 6/200
 - 12s - loss: 1.3369 - acc: 0.5435 - val_loss: 1.3493 - val_acc: 0.5614
Epoch 7/200
 - 12s - loss: 1.2791 - acc: 0.5809 - val_loss: 1.6395 - val_acc: 0.5434
Epoch 8/200
 - 12s - loss: 1.2238 - acc: 0.6234 - val_loss: 1.7797 - val_acc: 0.5016
Epoch 9/200
 - 12s - loss: 1.1784 - acc: 0.6501 - val_loss: 2.0594 - val_acc: 0.5285
Epoch 10/200
 - 12s - loss: 1.1265 - acc: 0.6648 - val_loss: 2.1184 - val_acc: 0.5600
Epoch 11/200
 - 12s - loss: 1.0863 - acc: 0.6736 - val_loss: 1.4520 - val_acc: 0.6311
Epoch 12/200
 - 12s - loss: 1.0561 - acc: 0.6782 - val_loss: 1.2817 - val_acc: 0.6540
Epoch 13/200
 - 12s - loss: 1.0299 - acc: 0.6817 - val_loss: 1.2308 - val_acc: 0.6668
Epoch 14/200
 - 12s - loss: 1.0082 - acc: 0.6847 - val_loss: 1.3035 - val_acc: 0.6628
Epoch 15/200
 - 12s - loss: 0.9925 - acc: 0.6855 - val_loss: 1.5494 - val_acc: 0.6483
Epoch 16/200
 - 12s - loss: 0.9722 - acc: 0.6862 - val_loss: 1.2626 - val_acc: 0.6677
Epoch 17/200
 - 12s - loss: 0.9514 - acc: 0.6874 - val_loss: 1.4156 - val_acc: 0.6703
Epoch 18/200
 - 12s - loss: 0.9390 - acc: 0.6887 - val_loss: 1.6608 - val_acc: 0.6417
Epoch 19/200
 - 12s - loss: 0.9189 - acc: 0.6902 - val_loss: 1.1948 - val_acc: 0.6733
Epoch 20/200
 - 12s - loss: 0.9018 - acc: 0.6915 - val_loss: 1.2678 - val_acc: 0.6739
Epoch 21/200
 - 12s - loss: 0.8878 - acc: 0.6922 - val_loss: 1.1800 - val_acc: 0.6769
Epoch 22/200
 - 12s - loss: 0.8745 - acc: 0.6925 - val_loss: 1.2262 - val_acc: 0.6766
Epoch 23/200
 - 12s - loss: 0.8673 - acc: 0.6933 - val_loss: 1.0963 - val_acc: 0.6785
Epoch 24/200
 - 12s - loss: 0.8570 - acc: 0.6934 - val_loss: 1.1268 - val_acc: 0.6796
Epoch 25/200
 - 12s - loss: 0.8500 - acc: 0.6937 - val_loss: 1.0912 - val_acc: 0.6795
Epoch 26/200
 - 12s - loss: 0.8408 - acc: 0.6943 - val_loss: 1.1701 - val_acc: 0.6786
Epoch 27/200
 - 12s - loss: 0.8518 - acc: 0.6908 - val_loss: 1.0178 - val_acc: 0.6749
Epoch 28/200
 - 12s - loss: 0.8440 - acc: 0.6930 - val_loss: 1.0880 - val_acc: 0.6727
Epoch 29/200
 - 12s - loss: 0.8292 - acc: 0.6948 - val_loss: 1.0025 - val_acc: 0.6828
Epoch 30/200
 - 12s - loss: 0.8319 - acc: 0.6962 - val_loss: 0.9849 - val_acc: 0.6805
Epoch 31/200
 - 12s - loss: 0.8133 - acc: 0.7028 - val_loss: 1.0126 - val_acc: 0.6877
Epoch 32/200
 - 12s - loss: 0.8089 - acc: 0.7074 - val_loss: 0.9799 - val_acc: 0.6908
Epoch 33/200
 - 12s - loss: 0.8345 - acc: 0.7146 - val_loss: 0.9263 - val_acc: 0.6965
Epoch 34/200
 - 12s - loss: 0.8261 - acc: 0.7152 - val_loss: 1.0021 - val_acc: 0.6908
Epoch 35/200
 - 12s - loss: 0.8037 - acc: 0.7212 - val_loss: 1.0181 - val_acc: 0.6939
Epoch 36/200
 - 12s - loss: 0.7914 - acc: 0.7278 - val_loss: 1.1343 - val_acc: 0.6918
Epoch 37/200
 - 12s - loss: 0.7864 - acc: 0.7321 - val_loss: 0.9665 - val_acc: 0.7050
Epoch 38/200
 - 12s - loss: 0.8101 - acc: 0.7285 - val_loss: 0.9367 - val_acc: 0.6816
Epoch 39/200
 - 12s - loss: 0.8039 - acc: 0.7354 - val_loss: 1.0827 - val_acc: 0.6927
Epoch 40/200
 - 12s - loss: 0.7830 - acc: 0.7374 - val_loss: 0.8874 - val_acc: 0.7109
Epoch 41/200
 - 12s - loss: 0.7668 - acc: 0.7428 - val_loss: 0.8760 - val_acc: 0.7198
Epoch 42/200
 - 12s - loss: 0.7600 - acc: 0.7464 - val_loss: 0.9017 - val_acc: 0.7171
Epoch 43/200
 - 12s - loss: 0.7559 - acc: 0.7462 - val_loss: 0.8861 - val_acc: 0.7216
Epoch 44/200
 - 12s - loss: 0.7591 - acc: 0.7468 - val_loss: 0.9552 - val_acc: 0.7168
Epoch 45/200
 - 12s - loss: 0.7475 - acc: 0.7510 - val_loss: 0.8666 - val_acc: 0.7217
Epoch 46/200
 - 12s - loss: 0.7561 - acc: 0.7469 - val_loss: 1.0253 - val_acc: 0.6938
Epoch 47/200
 - 12s - loss: 0.8183 - acc: 0.7253 - val_loss: 0.8711 - val_acc: 0.7274
Epoch 48/200
 - 12s - loss: 0.7889 - acc: 0.7434 - val_loss: 0.8833 - val_acc: 0.7255
Epoch 49/200
 - 12s - loss: 0.7529 - acc: 0.7534 - val_loss: 0.8406 - val_acc: 0.7328
Epoch 50/200
 - 12s - loss: 0.7311 - acc: 0.7587 - val_loss: 0.8195 - val_acc: 0.7401
Epoch 51/200
 - 12s - loss: 0.7181 - acc: 0.7641 - val_loss: 0.8557 - val_acc: 0.7377
Epoch 52/200
 - 12s - loss: 0.7160 - acc: 0.7684 - val_loss: 0.8112 - val_acc: 0.7472
Epoch 53/200
 - 12s - loss: 0.7041 - acc: 0.7713 - val_loss: 0.7942 - val_acc: 0.7515
Epoch 54/200
 - 12s - loss: 0.6879 - acc: 0.7756 - val_loss: 0.7865 - val_acc: 0.7569
Epoch 55/200
 - 12s - loss: 0.6768 - acc: 0.7821 - val_loss: 0.8416 - val_acc: 0.7537
Epoch 56/200
 - 12s - loss: 0.6705 - acc: 0.7866 - val_loss: 0.7949 - val_acc: 0.7652
Epoch 57/200
 - 12s - loss: 0.6636 - acc: 0.7940 - val_loss: 0.9770 - val_acc: 0.7520
Epoch 58/200
 - 12s - loss: 0.6974 - acc: 0.7906 - val_loss: 0.8385 - val_acc: 0.7696
Epoch 59/200
 - 12s - loss: 0.6916 - acc: 0.7961 - val_loss: 1.0735 - val_acc: 0.7451
Epoch 60/200
 - 12s - loss: 0.6727 - acc: 0.8059 - val_loss: 0.9566 - val_acc: 0.7675
Epoch 61/200
 - 12s - loss: 0.6471 - acc: 0.8132 - val_loss: 0.8425 - val_acc: 0.7851
Epoch 62/200
 - 12s - loss: 0.6385 - acc: 0.8149 - val_loss: 0.8746 - val_acc: 0.7820
Epoch 63/200
 - 12s - loss: 0.6454 - acc: 0.8141 - val_loss: 0.8073 - val_acc: 0.7857
Epoch 64/200
 - 12s - loss: 0.6500 - acc: 0.8174 - val_loss: 0.7557 - val_acc: 0.7859
Epoch 65/200
 - 12s - loss: 0.6443 - acc: 0.8205 - val_loss: 0.7769 - val_acc: 0.7868
Epoch 66/200
 - 12s - loss: 0.6256 - acc: 0.8274 - val_loss: 0.7638 - val_acc: 0.7898
Epoch 67/200
 - 12s - loss: 0.6156 - acc: 0.8291 - val_loss: 0.7955 - val_acc: 0.7862
Epoch 68/200
 - 12s - loss: 0.6087 - acc: 0.8302 - val_loss: 0.7374 - val_acc: 0.7928
Epoch 69/200
 - 12s - loss: 0.5984 - acc: 0.8346 - val_loss: 0.7442 - val_acc: 0.7913
Epoch 70/200
 - 12s - loss: 0.5966 - acc: 0.8340 - val_loss: 0.7438 - val_acc: 0.7925
Epoch 71/200
 - 12s - loss: 0.5857 - acc: 0.8361 - val_loss: 0.7428 - val_acc: 0.7865
Epoch 72/200
 - 12s - loss: 0.5749 - acc: 0.8371 - val_loss: 0.7484 - val_acc: 0.7959
Epoch 73/200
 - 12s - loss: 0.5686 - acc: 0.8402 - val_loss: 0.7602 - val_acc: 0.7978
Epoch 74/200
 - 12s - loss: 0.5790 - acc: 0.8375 - val_loss: 0.7474 - val_acc: 0.7945
Epoch 75/200
 - 12s - loss: 0.5701 - acc: 0.8410 - val_loss: 0.7555 - val_acc: 0.8052
Epoch 76/200
 - 12s - loss: 0.5728 - acc: 0.8409 - val_loss: 0.7417 - val_acc: 0.8058
Epoch 77/200
 - 12s - loss: 0.5754 - acc: 0.8404 - val_loss: 0.7232 - val_acc: 0.8128
Epoch 78/200
 - 12s - loss: 0.5624 - acc: 0.8436 - val_loss: 0.7077 - val_acc: 0.8097
Epoch 79/200
 - 12s - loss: 0.5704 - acc: 0.8423 - val_loss: 0.7709 - val_acc: 0.7937
Epoch 80/200
 - 12s - loss: 0.5713 - acc: 0.8404 - val_loss: 0.7755 - val_acc: 0.7900
Epoch 81/200
 - 12s - loss: 0.5604 - acc: 0.8425 - val_loss: 0.7471 - val_acc: 0.7923
Epoch 82/200
 - 12s - loss: 0.5627 - acc: 0.8416 - val_loss: 0.7498 - val_acc: 0.7947
Epoch 83/200
 - 12s - loss: 0.5603 - acc: 0.8424 - val_loss: 0.7573 - val_acc: 0.8038
Epoch 84/200
 - 12s - loss: 0.5423 - acc: 0.8467 - val_loss: 0.7187 - val_acc: 0.8143
Epoch 85/200
 - 12s - loss: 0.5387 - acc: 0.8470 - val_loss: 0.7181 - val_acc: 0.8073
Epoch 86/200
 - 12s - loss: 0.5324 - acc: 0.8495 - val_loss: 0.7019 - val_acc: 0.8106
Epoch 87/200
 - 12s - loss: 0.5343 - acc: 0.8477 - val_loss: 0.7193 - val_acc: 0.8120
Epoch 88/200
 - 12s - loss: 0.5314 - acc: 0.8490 - val_loss: 0.7041 - val_acc: 0.8045
Epoch 89/200
 - 12s - loss: 0.5327 - acc: 0.8479 - val_loss: 0.7203 - val_acc: 0.8078
Epoch 90/200
 - 12s - loss: 0.5308 - acc: 0.8476 - val_loss: 0.9975 - val_acc: 0.7465
Epoch 91/200
 - 12s - loss: 0.6035 - acc: 0.8243 - val_loss: 0.7583 - val_acc: 0.7906
Epoch 92/200
 - 12s - loss: 0.5749 - acc: 0.8350 - val_loss: 0.7760 - val_acc: 0.7968
Epoch 93/200
 - 12s - loss: 0.5642 - acc: 0.8378 - val_loss: 0.7780 - val_acc: 0.7818
Epoch 94/200
 - 12s - loss: 0.5524 - acc: 0.8429 - val_loss: 0.8513 - val_acc: 0.7704
Epoch 95/200
 - 12s - loss: 0.5400 - acc: 0.8452 - val_loss: 0.8576 - val_acc: 0.7758
Epoch 96/200
 - 12s - loss: 0.5360 - acc: 0.8457 - val_loss: 0.8360 - val_acc: 0.7708
Epoch 97/200
 - 12s - loss: 0.5306 - acc: 0.8473 - val_loss: 0.8471 - val_acc: 0.7699
Epoch 98/200
 - 12s - loss: 0.5271 - acc: 0.8488 - val_loss: 0.8568 - val_acc: 0.7635
Epoch 99/200
 - 12s - loss: 0.5272 - acc: 0.8495 - val_loss: 0.8933 - val_acc: 0.7632
Epoch 100/200
 - 12s - loss: 0.5177 - acc: 0.8511 - val_loss: 0.8080 - val_acc: 0.7890
Epoch 101/200
 - 12s - loss: 0.5212 - acc: 0.8501 - val_loss: 0.7837 - val_acc: 0.7960
Epoch 102/200
 - 12s - loss: 0.5146 - acc: 0.8518 - val_loss: 0.7299 - val_acc: 0.8074
Epoch 103/200
 - 12s - loss: 0.5239 - acc: 0.8487 - val_loss: 0.7671 - val_acc: 0.7940
Epoch 104/200
 - 12s - loss: 0.5156 - acc: 0.8506 - val_loss: 0.7878 - val_acc: 0.7775
Epoch 105/200
 - 12s - loss: 0.5265 - acc: 0.8492 - val_loss: 0.7096 - val_acc: 0.8077
Epoch 106/200
 - 12s - loss: 0.5124 - acc: 0.8528 - val_loss: 0.7908 - val_acc: 0.8005
Epoch 107/200
 - 12s - loss: 0.5723 - acc: 0.8361 - val_loss: 0.9725 - val_acc: 0.7366
Epoch 108/200
 - 12s - loss: 0.5403 - acc: 0.8461 - val_loss: 0.7207 - val_acc: 0.7945
Epoch 109/200
 - 12s - loss: 0.5319 - acc: 0.8488 - val_loss: 0.6762 - val_acc: 0.8128
Epoch 110/200
 - 12s - loss: 0.5226 - acc: 0.8509 - val_loss: 0.6624 - val_acc: 0.8154
Epoch 111/200
 - 12s - loss: 0.5222 - acc: 0.8526 - val_loss: 0.7136 - val_acc: 0.8110
Epoch 112/200
 - 12s - loss: 0.5196 - acc: 0.8538 - val_loss: 0.6909 - val_acc: 0.8172
Epoch 113/200
 - 12s - loss: 0.5249 - acc: 0.8514 - val_loss: 0.7232 - val_acc: 0.8005
Epoch 114/200
 - 12s - loss: 0.5122 - acc: 0.8543 - val_loss: 0.6621 - val_acc: 0.8189
Epoch 115/200
 - 12s - loss: 0.5088 - acc: 0.8540 - val_loss: 0.7165 - val_acc: 0.8127
Epoch 116/200
 - 12s - loss: 0.4954 - acc: 0.8564 - val_loss: 0.6954 - val_acc: 0.8182
Epoch 117/200
 - 12s - loss: 0.4942 - acc: 0.8570 - val_loss: 0.6713 - val_acc: 0.8236
Epoch 118/200
 - 12s - loss: 0.4936 - acc: 0.8578 - val_loss: 0.6782 - val_acc: 0.8234
Epoch 119/200
 - 12s - loss: 0.4930 - acc: 0.8578 - val_loss: 0.6371 - val_acc: 0.8298
Epoch 120/200
 - 12s - loss: 0.4915 - acc: 0.8584 - val_loss: 0.7303 - val_acc: 0.8027
Epoch 121/200
 - 12s - loss: 0.5047 - acc: 0.8544 - val_loss: 0.6981 - val_acc: 0.8146
Epoch 122/200
 - 12s - loss: 0.4920 - acc: 0.8596 - val_loss: 0.7171 - val_acc: 0.8098
Epoch 123/200
 - 12s - loss: 0.4948 - acc: 0.8585 - val_loss: 0.7188 - val_acc: 0.8043
Epoch 124/200
 - 12s - loss: 0.4915 - acc: 0.8604 - val_loss: 0.7308 - val_acc: 0.8094
Epoch 125/200
 - 12s - loss: 0.4983 - acc: 0.8593 - val_loss: 0.7073 - val_acc: 0.8180
Epoch 126/200
 - 12s - loss: 0.4902 - acc: 0.8606 - val_loss: 0.6503 - val_acc: 0.8258
Epoch 127/200
 - 12s - loss: 0.4993 - acc: 0.8553 - val_loss: 0.6508 - val_acc: 0.8265
Epoch 128/200
 - 12s - loss: 0.4937 - acc: 0.8590 - val_loss: 0.6820 - val_acc: 0.8168
Epoch 129/200
 - 12s - loss: 0.4851 - acc: 0.8617 - val_loss: 0.6608 - val_acc: 0.8172
Epoch 130/200
 - 12s - loss: 0.4785 - acc: 0.8631 - val_loss: 0.6387 - val_acc: 0.8217
Epoch 131/200
 - 12s - loss: 0.4813 - acc: 0.8623 - val_loss: 0.6602 - val_acc: 0.8277
Epoch 132/200
 - 12s - loss: 0.4724 - acc: 0.8652 - val_loss: 0.6583 - val_acc: 0.8228
Epoch 133/200
 - 12s - loss: 0.4801 - acc: 0.8640 - val_loss: 0.6588 - val_acc: 0.8263
Epoch 134/200
 - 12s - loss: 0.4761 - acc: 0.8640 - val_loss: 0.6272 - val_acc: 0.8332
Epoch 135/200
 - 12s - loss: 0.4743 - acc: 0.8644 - val_loss: 0.6674 - val_acc: 0.8230
Epoch 136/200
 - 12s - loss: 0.4824 - acc: 0.8630 - val_loss: 0.6861 - val_acc: 0.8203
Epoch 137/200
 - 12s - loss: 0.4711 - acc: 0.8664 - val_loss: 0.6495 - val_acc: 0.8283
Epoch 138/200
 - 12s - loss: 0.4711 - acc: 0.8665 - val_loss: 0.6556 - val_acc: 0.8292
Epoch 139/200
 - 12s - loss: 0.4620 - acc: 0.8684 - val_loss: 0.6347 - val_acc: 0.8281
Epoch 140/200
 - 12s - loss: 0.4598 - acc: 0.8694 - val_loss: 0.6796 - val_acc: 0.8224
Epoch 141/200
 - 12s - loss: 0.4663 - acc: 0.8687 - val_loss: 0.6570 - val_acc: 0.8330
Epoch 142/200
 - 12s - loss: 0.4673 - acc: 0.8695 - val_loss: 0.7249 - val_acc: 0.8101
Epoch 143/200
 - 12s - loss: 0.4703 - acc: 0.8680 - val_loss: 0.7238 - val_acc: 0.8198
Epoch 144/200
 - 12s - loss: 0.4721 - acc: 0.8682 - val_loss: 0.6468 - val_acc: 0.8303
Epoch 145/200
 - 12s - loss: 0.4634 - acc: 0.8700 - val_loss: 0.6363 - val_acc: 0.8333
Epoch 146/200
 - 12s - loss: 0.4573 - acc: 0.8710 - val_loss: 0.6163 - val_acc: 0.8360
Epoch 147/200
 - 12s - loss: 0.4597 - acc: 0.8698 - val_loss: 0.6482 - val_acc: 0.8215
Epoch 148/200
 - 12s - loss: 0.4523 - acc: 0.8734 - val_loss: 0.6535 - val_acc: 0.8302
Epoch 149/200
 - 12s - loss: 0.4533 - acc: 0.8722 - val_loss: 0.6256 - val_acc: 0.8311
Epoch 150/200
 - 12s - loss: 0.4528 - acc: 0.8729 - val_loss: 0.6478 - val_acc: 0.8267
Epoch 151/200
 - 12s - loss: 0.4533 - acc: 0.8723 - val_loss: 0.6468 - val_acc: 0.8300
Epoch 152/200
 - 12s - loss: 0.4435 - acc: 0.8750 - val_loss: 0.6315 - val_acc: 0.8315
Epoch 153/200
 - 12s - loss: 0.4496 - acc: 0.8739 - val_loss: 0.6118 - val_acc: 0.8373
Epoch 154/200
 - 12s - loss: 0.4510 - acc: 0.8735 - val_loss: 0.6255 - val_acc: 0.8380
Epoch 155/200
 - 12s - loss: 0.4538 - acc: 0.8729 - val_loss: 0.6243 - val_acc: 0.8223
Epoch 156/200
 - 12s - loss: 0.4520 - acc: 0.8734 - val_loss: 0.6347 - val_acc: 0.8251
Epoch 157/200
 - 12s - loss: 0.4505 - acc: 0.8742 - val_loss: 0.6310 - val_acc: 0.8318
Epoch 158/200
 - 12s - loss: 0.4504 - acc: 0.8743 - val_loss: 0.6605 - val_acc: 0.8203
Epoch 159/200
 - 12s - loss: 0.4496 - acc: 0.8747 - val_loss: 0.6075 - val_acc: 0.8391
Epoch 160/200
 - 12s - loss: 0.4456 - acc: 0.8761 - val_loss: 0.6389 - val_acc: 0.8379
Epoch 161/200
 - 12s - loss: 0.4438 - acc: 0.8757 - val_loss: 0.6234 - val_acc: 0.8378
Epoch 162/200
 - 12s - loss: 0.4479 - acc: 0.8754 - val_loss: 0.6000 - val_acc: 0.8421
Epoch 163/200
 - 12s - loss: 0.4462 - acc: 0.8760 - val_loss: 0.6142 - val_acc: 0.8374
Epoch 164/200
 - 12s - loss: 0.4409 - acc: 0.8772 - val_loss: 0.6187 - val_acc: 0.8387
Epoch 165/200
 - 12s - loss: 0.4522 - acc: 0.8742 - val_loss: 0.6563 - val_acc: 0.8376
Epoch 166/200
 - 12s - loss: 0.4471 - acc: 0.8762 - val_loss: 0.6479 - val_acc: 0.8299
Epoch 167/200
 - 12s - loss: 0.4470 - acc: 0.8765 - val_loss: 0.6593 - val_acc: 0.8241
Epoch 168/200
 - 12s - loss: 0.4526 - acc: 0.8766 - val_loss: 0.6306 - val_acc: 0.8346
Epoch 169/200
 - 12s - loss: 0.4469 - acc: 0.8771 - val_loss: 0.6114 - val_acc: 0.8413
Epoch 170/200
 - 12s - loss: 0.4415 - acc: 0.8780 - val_loss: 0.6245 - val_acc: 0.8356
Epoch 171/200
 - 12s - loss: 0.4338 - acc: 0.8795 - val_loss: 0.6153 - val_acc: 0.8366
Epoch 172/200
 - 12s - loss: 0.4319 - acc: 0.8794 - val_loss: 0.6254 - val_acc: 0.8368
Epoch 173/200
 - 12s - loss: 0.4315 - acc: 0.8792 - val_loss: 0.6380 - val_acc: 0.8363
Epoch 174/200
 - 12s - loss: 0.4294 - acc: 0.8800 - val_loss: 0.6041 - val_acc: 0.8411
Epoch 175/200
 - 12s - loss: 0.4261 - acc: 0.8811 - val_loss: 0.6210 - val_acc: 0.8367
Epoch 176/200
 - 12s - loss: 0.4322 - acc: 0.8794 - val_loss: 0.6387 - val_acc: 0.8371
Epoch 177/200
 - 12s - loss: 0.4340 - acc: 0.8799 - val_loss: 0.6067 - val_acc: 0.8389
Epoch 178/200
 - 12s - loss: 0.4302 - acc: 0.8803 - val_loss: 0.6044 - val_acc: 0.8408
Epoch 179/200
 - 12s - loss: 0.4287 - acc: 0.8808 - val_loss: 0.5800 - val_acc: 0.8422
Epoch 180/200
 - 12s - loss: 0.4319 - acc: 0.8797 - val_loss: 0.6063 - val_acc: 0.8396
Epoch 181/200
 - 12s - loss: 0.4297 - acc: 0.8800 - val_loss: 0.6090 - val_acc: 0.8387
Epoch 182/200
 - 12s - loss: 0.4296 - acc: 0.8792 - val_loss: 0.6046 - val_acc: 0.8410
Epoch 183/200
 - 12s - loss: 0.4275 - acc: 0.8805 - val_loss: 0.5962 - val_acc: 0.8394
Epoch 184/200
 - 12s - loss: 0.4250 - acc: 0.8811 - val_loss: 0.6001 - val_acc: 0.8401
Epoch 185/200
 - 12s - loss: 0.4279 - acc: 0.8805 - val_loss: 0.6220 - val_acc: 0.8309
Epoch 186/200
 - 12s - loss: 0.4306 - acc: 0.8795 - val_loss: 0.6064 - val_acc: 0.8353
Epoch 187/200
 - 12s - loss: 0.4272 - acc: 0.8806 - val_loss: 0.6104 - val_acc: 0.8388
Epoch 188/200
 - 12s - loss: 0.4265 - acc: 0.8806 - val_loss: 0.6311 - val_acc: 0.8310
Epoch 189/200
 - 12s - loss: 0.4242 - acc: 0.8814 - val_loss: 0.5928 - val_acc: 0.8465
Epoch 190/200
 - 12s - loss: 0.4255 - acc: 0.8806 - val_loss: 0.6031 - val_acc: 0.8419
Epoch 191/200
 - 12s - loss: 0.4313 - acc: 0.8779 - val_loss: 0.6266 - val_acc: 0.8355
Epoch 192/200
 - 12s - loss: 0.4352 - acc: 0.8773 - val_loss: 0.6063 - val_acc: 0.8419
Epoch 193/200
 - 12s - loss: 0.4260 - acc: 0.8814 - val_loss: 0.5840 - val_acc: 0.8459
Epoch 194/200
 - 12s - loss: 0.4248 - acc: 0.8822 - val_loss: 0.5916 - val_acc: 0.8455
Epoch 195/200
 - 12s - loss: 0.4232 - acc: 0.8828 - val_loss: 0.5673 - val_acc: 0.8520
Epoch 196/200
 - 12s - loss: 0.4229 - acc: 0.8819 - val_loss: 0.5907 - val_acc: 0.8418
Epoch 197/200
 - 12s - loss: 0.4244 - acc: 0.8813 - val_loss: 0.5743 - val_acc: 0.8423
Epoch 198/200
 - 12s - loss: 0.4184 - acc: 0.8831 - val_loss: 0.5883 - val_acc: 0.8397
Epoch 199/200
 - 12s - loss: 0.4188 - acc: 0.8829 - val_loss: 0.5948 - val_acc: 0.8449
Epoch 200/200
 - 12s - loss: 0.4198 - acc: 0.8826 - val_loss: 0.5836 - val_acc: 0.8488
Using TensorFlow backend.


Elapsed time for Keras training (s):  2481.331517



End of UNET training

2020-03-05 11:12:22.527272: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:12:22.616041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:12:22.616061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:12:23.122551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:12:23.122571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:12:23.122574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:12:23.123205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20768 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
UNET MODEL =  3
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 224, 224, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 224, 224, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 224, 224, 64) 256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 224, 224, 64) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 224, 224, 64) 36928       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 224, 224, 64) 256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 224, 224, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64) 0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 112, 112, 64) 0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 112, 112, 128 73856       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 112, 112, 128 512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 112, 112, 128 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 112, 112, 128 147584      activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 112, 112, 128 512         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 112, 112, 128 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 128)  0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 56, 56, 128)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 56, 56, 256)  295168      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 56, 56, 256)  1024        conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 56, 56, 256)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 56, 56, 256)  590080      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 56, 56, 256)  1024        conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 56, 256)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0           activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 28, 28, 256)  0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 512)  1180160     dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 512)  2048        conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 512)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 512)  2359808     activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 512)  2048        conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 512)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 14, 14, 512)  0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 14, 1024) 4719616     dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 14, 14, 1024) 4096        conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 14, 14, 1024) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 14, 14, 1024) 9438208     activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 14, 14, 1024) 4096        conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 14, 14, 1024) 0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 512)  4719104     dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 28, 1024) 0           conv2d_transpose_1[0][0]         
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28, 28, 1024) 0           concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 512)  4719104     dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 28, 512)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 512)  2359808     activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 28, 512)  2048        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 28, 512)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 256)  1179904     activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 56, 56, 512)  0           conv2d_transpose_2[0][0]         
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 56, 56, 512)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 56, 256)  1179904     dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 56, 56, 256)  1024        conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 56, 56, 256)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 56, 256)  590080      activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 56, 56, 256)  1024        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 56, 56, 256)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 112, 112, 128 295040      activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 112, 112, 256 0           conv2d_transpose_3[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 112, 112, 256 0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 112, 112, 128 295040      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 112, 112, 128 512         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 112, 112, 128 0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 112, 112, 128 147584      activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 112, 112, 128 512         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 112, 112, 128 0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 224, 224, 64) 73792       activation_16[0][0]              
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 224, 224, 128 0           conv2d_transpose_4[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 224, 224, 128 0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 224, 224, 64) 73792       dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 224, 224, 64) 256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 224, 224, 64) 0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 224, 224, 64) 36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 224, 224, 64) 256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 224, 224, 64) 0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 224, 224, 12) 6924        activation_18[0][0]              
==================================================================================================
Total params: 34,543,756
Trainable params: 34,531,980
Non-trainable params: 11,776
__________________________________________________________________________________________________
(311, 224, 224, 3) (311, 224, 224, 12)
(56, 224, 224, 3) (56, 224, 224, 12)
Train on 311 samples, validate on 56 samples
Epoch 1/200
 - 23s - loss: 2.5857 - acc: 0.3499 - val_loss: 1.7748 - val_acc: 0.3190
Epoch 2/200
 - 11s - loss: 1.7255 - acc: 0.3570 - val_loss: 1.6991 - val_acc: 0.3223
Epoch 3/200
 - 11s - loss: 1.6492 - acc: 0.4328 - val_loss: 1.6133 - val_acc: 0.4423
Epoch 4/200
 - 11s - loss: 1.5820 - acc: 0.4430 - val_loss: 1.5637 - val_acc: 0.4496
Epoch 5/200
 - 11s - loss: 1.5336 - acc: 0.4531 - val_loss: 1.5382 - val_acc: 0.4606
Epoch 6/200
 - 11s - loss: 1.4909 - acc: 0.4770 - val_loss: 1.5163 - val_acc: 0.4787
Epoch 7/200
 - 11s - loss: 1.4486 - acc: 0.5034 - val_loss: 1.5067 - val_acc: 0.4874
Epoch 8/200
 - 11s - loss: 1.4190 - acc: 0.5288 - val_loss: 1.4725 - val_acc: 0.5036
Epoch 9/200
 - 11s - loss: 1.3795 - acc: 0.5586 - val_loss: 1.4323 - val_acc: 0.5180
Epoch 10/200
 - 11s - loss: 1.3399 - acc: 0.5817 - val_loss: 1.3959 - val_acc: 0.5447
Epoch 11/200
 - 11s - loss: 1.3045 - acc: 0.5978 - val_loss: 1.3877 - val_acc: 0.5470
Epoch 12/200
 - 11s - loss: 1.2704 - acc: 0.6120 - val_loss: 1.3411 - val_acc: 0.5669
Epoch 13/200
 - 11s - loss: 1.2483 - acc: 0.6231 - val_loss: 1.3549 - val_acc: 0.5710
Epoch 14/200
 - 11s - loss: 1.2147 - acc: 0.6351 - val_loss: 1.3198 - val_acc: 0.5945
Epoch 15/200
 - 11s - loss: 1.1772 - acc: 0.6433 - val_loss: 1.3548 - val_acc: 0.5868
Epoch 16/200
 - 11s - loss: 1.1425 - acc: 0.6490 - val_loss: 1.6421 - val_acc: 0.5583
Epoch 17/200
 - 11s - loss: 1.1162 - acc: 0.6541 - val_loss: 1.2735 - val_acc: 0.6146
Epoch 18/200
 - 11s - loss: 1.0898 - acc: 0.6602 - val_loss: 1.2943 - val_acc: 0.6221
Epoch 19/200
 - 11s - loss: 1.0704 - acc: 0.6639 - val_loss: 1.5218 - val_acc: 0.5986
Epoch 20/200
 - 11s - loss: 1.0581 - acc: 0.6671 - val_loss: 1.3416 - val_acc: 0.6228
Epoch 21/200
 - 11s - loss: 1.0474 - acc: 0.6693 - val_loss: 1.3860 - val_acc: 0.6193
Epoch 22/200
 - 11s - loss: 1.0386 - acc: 0.6714 - val_loss: 1.5228 - val_acc: 0.6155
Epoch 23/200
 - 11s - loss: 1.0260 - acc: 0.6739 - val_loss: 1.3674 - val_acc: 0.6341
Epoch 24/200
 - 11s - loss: 1.0173 - acc: 0.6758 - val_loss: 1.6409 - val_acc: 0.6231
Epoch 25/200
 - 11s - loss: 1.0225 - acc: 0.6765 - val_loss: 1.2797 - val_acc: 0.6298
Epoch 26/200
 - 11s - loss: 1.0245 - acc: 0.6749 - val_loss: 1.1021 - val_acc: 0.6654
Epoch 27/200
 - 11s - loss: 0.9982 - acc: 0.6793 - val_loss: 1.1503 - val_acc: 0.6648
Epoch 28/200
 - 11s - loss: 0.9911 - acc: 0.6813 - val_loss: 1.1440 - val_acc: 0.6668
Epoch 29/200
 - 11s - loss: 1.0325 - acc: 0.6718 - val_loss: 1.3639 - val_acc: 0.5762
Epoch 30/200
 - 11s - loss: 1.0913 - acc: 0.6518 - val_loss: 1.3889 - val_acc: 0.5595
Epoch 31/200
 - 11s - loss: 1.0421 - acc: 0.6724 - val_loss: 1.3298 - val_acc: 0.5765
Epoch 32/200
 - 11s - loss: 1.0002 - acc: 0.6809 - val_loss: 1.2673 - val_acc: 0.6142
Epoch 33/200
 - 11s - loss: 0.9877 - acc: 0.6823 - val_loss: 1.2152 - val_acc: 0.6326
Epoch 34/200
 - 11s - loss: 0.9741 - acc: 0.6844 - val_loss: 1.1577 - val_acc: 0.6423
Epoch 35/200
 - 11s - loss: 0.9645 - acc: 0.6858 - val_loss: 1.9211 - val_acc: 0.5516
Epoch 36/200
 - 11s - loss: 1.1381 - acc: 0.6427 - val_loss: 1.4487 - val_acc: 0.5581
Epoch 37/200
 - 11s - loss: 1.0421 - acc: 0.6724 - val_loss: 1.3616 - val_acc: 0.6034
Epoch 38/200
 - 11s - loss: 0.9995 - acc: 0.6815 - val_loss: 1.2853 - val_acc: 0.6493
Epoch 39/200
 - 11s - loss: 0.9711 - acc: 0.6844 - val_loss: 1.2103 - val_acc: 0.6575
Epoch 40/200
 - 11s - loss: 0.9626 - acc: 0.6855 - val_loss: 1.3574 - val_acc: 0.6338
Epoch 41/200
 - 11s - loss: 0.9546 - acc: 0.6855 - val_loss: 1.4692 - val_acc: 0.6339
Epoch 42/200
 - 11s - loss: 0.9451 - acc: 0.6869 - val_loss: 1.8394 - val_acc: 0.6210
Epoch 43/200
 - 11s - loss: 0.9323 - acc: 0.6887 - val_loss: 1.8582 - val_acc: 0.6301
Epoch 44/200
 - 11s - loss: 0.9284 - acc: 0.6884 - val_loss: 1.8961 - val_acc: 0.6287
Epoch 45/200
 - 11s - loss: 0.9217 - acc: 0.6893 - val_loss: 1.8238 - val_acc: 0.6389
Epoch 46/200
 - 11s - loss: 0.9156 - acc: 0.6886 - val_loss: 1.5995 - val_acc: 0.6555
Epoch 47/200
 - 11s - loss: 0.9049 - acc: 0.6904 - val_loss: 1.7378 - val_acc: 0.6499
Epoch 48/200
 - 11s - loss: 0.8992 - acc: 0.6909 - val_loss: 1.6038 - val_acc: 0.6619
Epoch 49/200
 - 11s - loss: 0.8902 - acc: 0.6917 - val_loss: 1.6811 - val_acc: 0.6621
Epoch 50/200
 - 11s - loss: 0.8893 - acc: 0.6915 - val_loss: 1.6176 - val_acc: 0.6667
Epoch 51/200
 - 11s - loss: 0.8856 - acc: 0.6920 - val_loss: 1.8793 - val_acc: 0.6491
Epoch 52/200
 - 11s - loss: 0.8790 - acc: 0.6928 - val_loss: 1.8750 - val_acc: 0.6525
Epoch 53/200
 - 11s - loss: 0.8726 - acc: 0.6947 - val_loss: 1.6784 - val_acc: 0.6630
Epoch 54/200
 - 11s - loss: 0.8725 - acc: 0.6970 - val_loss: 1.6623 - val_acc: 0.6686
Epoch 55/200
 - 11s - loss: 0.8687 - acc: 0.6996 - val_loss: 1.5313 - val_acc: 0.6738
Epoch 56/200
 - 11s - loss: 0.8743 - acc: 0.7012 - val_loss: 1.6767 - val_acc: 0.6655
Epoch 57/200
 - 11s - loss: 0.8846 - acc: 0.7024 - val_loss: 1.5298 - val_acc: 0.6753
Epoch 58/200
 - 11s - loss: 0.8656 - acc: 0.7076 - val_loss: 1.2367 - val_acc: 0.6867
Epoch 59/200
 - 11s - loss: 0.8592 - acc: 0.7095 - val_loss: 1.6386 - val_acc: 0.6697
Epoch 60/200
 - 11s - loss: 0.8489 - acc: 0.7115 - val_loss: 1.3447 - val_acc: 0.6804
Epoch 61/200
 - 11s - loss: 0.8442 - acc: 0.7133 - val_loss: 1.2656 - val_acc: 0.6824
Epoch 62/200
 - 11s - loss: 0.8374 - acc: 0.7158 - val_loss: 1.3633 - val_acc: 0.6817
Epoch 63/200
 - 11s - loss: 0.8384 - acc: 0.7161 - val_loss: 1.1897 - val_acc: 0.6896
Epoch 64/200
 - 11s - loss: 0.8376 - acc: 0.7172 - val_loss: 1.2204 - val_acc: 0.6905
Epoch 65/200
 - 11s - loss: 0.8268 - acc: 0.7199 - val_loss: 1.2124 - val_acc: 0.6886
Epoch 66/200
 - 11s - loss: 0.8242 - acc: 0.7202 - val_loss: 1.1879 - val_acc: 0.6870
Epoch 67/200
 - 11s - loss: 0.8229 - acc: 0.7217 - val_loss: 1.1158 - val_acc: 0.6976
Epoch 68/200
 - 11s - loss: 0.8166 - acc: 0.7249 - val_loss: 1.1870 - val_acc: 0.6934
Epoch 69/200
 - 11s - loss: 0.8317 - acc: 0.7210 - val_loss: 0.9261 - val_acc: 0.7096
Epoch 70/200
 - 11s - loss: 0.8201 - acc: 0.7246 - val_loss: 1.1107 - val_acc: 0.6935
Epoch 71/200
 - 11s - loss: 0.8151 - acc: 0.7260 - val_loss: 1.1688 - val_acc: 0.6909
Epoch 72/200
 - 11s - loss: 0.8110 - acc: 0.7263 - val_loss: 1.3233 - val_acc: 0.6856
Epoch 73/200
 - 11s - loss: 0.8425 - acc: 0.7187 - val_loss: 1.2900 - val_acc: 0.6903
Epoch 74/200
 - 11s - loss: 0.8285 - acc: 0.7261 - val_loss: 1.1464 - val_acc: 0.6985
Epoch 75/200
 - 11s - loss: 0.8131 - acc: 0.7278 - val_loss: 1.0471 - val_acc: 0.7049
Epoch 76/200
 - 11s - loss: 0.8076 - acc: 0.7298 - val_loss: 1.0442 - val_acc: 0.7075
Epoch 77/200
 - 11s - loss: 0.8086 - acc: 0.7302 - val_loss: 1.0129 - val_acc: 0.7088
Epoch 78/200
 - 11s - loss: 0.8125 - acc: 0.7278 - val_loss: 1.1718 - val_acc: 0.6961
Epoch 79/200
 - 11s - loss: 0.8106 - acc: 0.7295 - val_loss: 1.0466 - val_acc: 0.7054
Epoch 80/200
 - 11s - loss: 0.7973 - acc: 0.7332 - val_loss: 1.0108 - val_acc: 0.7095
Epoch 81/200
 - 11s - loss: 0.7926 - acc: 0.7332 - val_loss: 1.0171 - val_acc: 0.7122
Epoch 82/200
 - 11s - loss: 0.7875 - acc: 0.7361 - val_loss: 1.0553 - val_acc: 0.7088
Epoch 83/200
 - 11s - loss: 0.7805 - acc: 0.7369 - val_loss: 0.9728 - val_acc: 0.7154
Epoch 84/200
 - 11s - loss: 0.7807 - acc: 0.7371 - val_loss: 0.9923 - val_acc: 0.7160
Epoch 85/200
 - 11s - loss: 0.7809 - acc: 0.7389 - val_loss: 0.9456 - val_acc: 0.7204
Epoch 86/200
 - 11s - loss: 0.7801 - acc: 0.7402 - val_loss: 1.0312 - val_acc: 0.7139
Epoch 87/200
 - 11s - loss: 0.7923 - acc: 0.7363 - val_loss: 1.0483 - val_acc: 0.7128
Epoch 88/200
 - 11s - loss: 0.7824 - acc: 0.7409 - val_loss: 1.0705 - val_acc: 0.7116
Epoch 89/200
 - 11s - loss: 0.7741 - acc: 0.7403 - val_loss: 0.9410 - val_acc: 0.7246
Epoch 90/200
 - 11s - loss: 0.7714 - acc: 0.7423 - val_loss: 0.9426 - val_acc: 0.7220
Epoch 91/200
 - 11s - loss: 0.7690 - acc: 0.7423 - val_loss: 0.9287 - val_acc: 0.7257
Epoch 92/200
 - 11s - loss: 0.7633 - acc: 0.7460 - val_loss: 0.9662 - val_acc: 0.7200
Epoch 93/200
 - 11s - loss: 0.7585 - acc: 0.7465 - val_loss: 0.9989 - val_acc: 0.7193
Epoch 94/200
 - 11s - loss: 0.7620 - acc: 0.7483 - val_loss: 0.9925 - val_acc: 0.7211
Epoch 95/200
 - 11s - loss: 0.7665 - acc: 0.7463 - val_loss: 1.0184 - val_acc: 0.7193
Epoch 96/200
 - 11s - loss: 0.7657 - acc: 0.7469 - val_loss: 0.9456 - val_acc: 0.7272
Epoch 97/200
 - 11s - loss: 0.7591 - acc: 0.7480 - val_loss: 0.9469 - val_acc: 0.7231
Epoch 98/200
 - 11s - loss: 0.7540 - acc: 0.7504 - val_loss: 1.0252 - val_acc: 0.7183
Epoch 99/200
 - 11s - loss: 0.7548 - acc: 0.7510 - val_loss: 0.9677 - val_acc: 0.7273
Epoch 100/200
 - 11s - loss: 0.7667 - acc: 0.7486 - val_loss: 1.1501 - val_acc: 0.6931
Epoch 101/200
 - 11s - loss: 0.8123 - acc: 0.7367 - val_loss: 1.0627 - val_acc: 0.7035
Epoch 102/200
 - 11s - loss: 0.7786 - acc: 0.7480 - val_loss: 0.9062 - val_acc: 0.7242
Epoch 103/200
 - 11s - loss: 0.7685 - acc: 0.7488 - val_loss: 1.0889 - val_acc: 0.7112
Epoch 104/200
 - 11s - loss: 0.7609 - acc: 0.7494 - val_loss: 0.8769 - val_acc: 0.7336
Epoch 105/200
 - 11s - loss: 0.7759 - acc: 0.7517 - val_loss: 0.9404 - val_acc: 0.7348
Epoch 106/200
 - 11s - loss: 0.7678 - acc: 0.7514 - val_loss: 0.8854 - val_acc: 0.7397
Epoch 107/200
 - 11s - loss: 0.7614 - acc: 0.7533 - val_loss: 0.8851 - val_acc: 0.7386
Epoch 108/200
 - 11s - loss: 0.7595 - acc: 0.7524 - val_loss: 0.9518 - val_acc: 0.7326
Epoch 109/200
 - 11s - loss: 0.7490 - acc: 0.7533 - val_loss: 0.8863 - val_acc: 0.7371
Epoch 110/200
 - 11s - loss: 0.7441 - acc: 0.7561 - val_loss: 0.9230 - val_acc: 0.7349
Epoch 111/200
 - 11s - loss: 0.7402 - acc: 0.7565 - val_loss: 0.8920 - val_acc: 0.7363
Epoch 112/200
 - 11s - loss: 0.7373 - acc: 0.7578 - val_loss: 0.9504 - val_acc: 0.7306
Epoch 113/200
 - 11s - loss: 0.7352 - acc: 0.7583 - val_loss: 0.8716 - val_acc: 0.7393
Epoch 114/200
 - 11s - loss: 0.7317 - acc: 0.7592 - val_loss: 0.9123 - val_acc: 0.7309
Epoch 115/200
 - 11s - loss: 0.7386 - acc: 0.7576 - val_loss: 0.8596 - val_acc: 0.7404
Epoch 116/200
 - 11s - loss: 0.7626 - acc: 0.7523 - val_loss: 1.0765 - val_acc: 0.7177
Epoch 117/200
 - 11s - loss: 0.7636 - acc: 0.7503 - val_loss: 0.9397 - val_acc: 0.7298
Epoch 118/200
 - 11s - loss: 0.7467 - acc: 0.7542 - val_loss: 0.8878 - val_acc: 0.7386
Epoch 119/200
 - 11s - loss: 0.7370 - acc: 0.7582 - val_loss: 0.8358 - val_acc: 0.7398
Epoch 120/200
 - 11s - loss: 0.7562 - acc: 0.7553 - val_loss: 0.8489 - val_acc: 0.7333
Epoch 121/200
 - 11s - loss: 0.7702 - acc: 0.7485 - val_loss: 0.8373 - val_acc: 0.7386
Epoch 122/200
 - 11s - loss: 0.7475 - acc: 0.7544 - val_loss: 0.8164 - val_acc: 0.7393
Epoch 123/200
 - 11s - loss: 0.7499 - acc: 0.7534 - val_loss: 0.8759 - val_acc: 0.7322
Epoch 124/200
 - 11s - loss: 0.7361 - acc: 0.7583 - val_loss: 0.8644 - val_acc: 0.7340
Epoch 125/200
 - 11s - loss: 0.7336 - acc: 0.7589 - val_loss: 0.8616 - val_acc: 0.7350
Epoch 126/200
 - 11s - loss: 0.7339 - acc: 0.7596 - val_loss: 0.8457 - val_acc: 0.7375
Epoch 127/200
 - 11s - loss: 0.7212 - acc: 0.7619 - val_loss: 0.8949 - val_acc: 0.7209
Epoch 128/200
 - 11s - loss: 0.7210 - acc: 0.7618 - val_loss: 0.8879 - val_acc: 0.7383
Epoch 129/200
 - 11s - loss: 0.7176 - acc: 0.7617 - val_loss: 0.8402 - val_acc: 0.7370
Epoch 130/200
 - 11s - loss: 0.7184 - acc: 0.7627 - val_loss: 0.8628 - val_acc: 0.7373
Epoch 131/200
 - 11s - loss: 0.7131 - acc: 0.7646 - val_loss: 0.8631 - val_acc: 0.7377
Epoch 132/200
 - 11s - loss: 0.7215 - acc: 0.7631 - val_loss: 0.8376 - val_acc: 0.7392
Epoch 133/200
 - 11s - loss: 0.7125 - acc: 0.7653 - val_loss: 0.7979 - val_acc: 0.7469
Epoch 134/200
 - 11s - loss: 0.7109 - acc: 0.7643 - val_loss: 0.8261 - val_acc: 0.7434
Epoch 135/200
 - 11s - loss: 0.7090 - acc: 0.7645 - val_loss: 0.8312 - val_acc: 0.7421
Epoch 136/200
 - 11s - loss: 0.7086 - acc: 0.7653 - val_loss: 0.8685 - val_acc: 0.7397
Epoch 137/200
 - 11s - loss: 0.7036 - acc: 0.7678 - val_loss: 0.8635 - val_acc: 0.7404
Epoch 138/200
 - 11s - loss: 0.7086 - acc: 0.7650 - val_loss: 0.8622 - val_acc: 0.7374
Epoch 139/200
 - 11s - loss: 0.7122 - acc: 0.7643 - val_loss: 0.8797 - val_acc: 0.7392
Epoch 140/200
 - 11s - loss: 0.6971 - acc: 0.7681 - val_loss: 0.8319 - val_acc: 0.7424
Epoch 141/200
 - 11s - loss: 0.6948 - acc: 0.7689 - val_loss: 0.8286 - val_acc: 0.7427
Epoch 142/200
 - 11s - loss: 0.6930 - acc: 0.7699 - val_loss: 0.9563 - val_acc: 0.7339
Epoch 143/200
 - 11s - loss: 0.6946 - acc: 0.7697 - val_loss: 1.0099 - val_acc: 0.6616
Epoch 144/200
 - 11s - loss: 0.7165 - acc: 0.7679 - val_loss: 0.8304 - val_acc: 0.7406
Epoch 145/200
 - 11s - loss: 0.7123 - acc: 0.7696 - val_loss: 0.8284 - val_acc: 0.7407
Epoch 146/200
 - 11s - loss: 0.7128 - acc: 0.7656 - val_loss: 0.8124 - val_acc: 0.7416
Epoch 147/200
 - 11s - loss: 0.6927 - acc: 0.7712 - val_loss: 0.8210 - val_acc: 0.7454
Epoch 148/200
 - 11s - loss: 0.6876 - acc: 0.7739 - val_loss: 0.8193 - val_acc: 0.7447
Epoch 149/200
 - 11s - loss: 0.6888 - acc: 0.7727 - val_loss: 0.8245 - val_acc: 0.7456
Epoch 150/200
 - 11s - loss: 0.6883 - acc: 0.7741 - val_loss: 0.8308 - val_acc: 0.7460
Epoch 151/200
 - 11s - loss: 0.6868 - acc: 0.7749 - val_loss: 0.7795 - val_acc: 0.7507
Epoch 152/200
 - 11s - loss: 0.6785 - acc: 0.7754 - val_loss: 0.7995 - val_acc: 0.7504
Epoch 153/200
 - 11s - loss: 0.6771 - acc: 0.7762 - val_loss: 0.8155 - val_acc: 0.7496
Epoch 154/200
 - 11s - loss: 0.6802 - acc: 0.7761 - val_loss: 0.8342 - val_acc: 0.7505
Epoch 155/200
 - 11s - loss: 0.6913 - acc: 0.7745 - val_loss: 0.9201 - val_acc: 0.7393
Epoch 156/200
 - 11s - loss: 0.6828 - acc: 0.7791 - val_loss: 0.9286 - val_acc: 0.7391
Epoch 157/200
 - 11s - loss: 0.6764 - acc: 0.7797 - val_loss: 0.8414 - val_acc: 0.7471
Epoch 158/200
 - 11s - loss: 0.6741 - acc: 0.7795 - val_loss: 0.7983 - val_acc: 0.7532
Epoch 159/200
 - 11s - loss: 0.6746 - acc: 0.7799 - val_loss: 0.7738 - val_acc: 0.7583
Epoch 160/200
 - 11s - loss: 0.6666 - acc: 0.7841 - val_loss: 0.7727 - val_acc: 0.7567
Epoch 161/200
 - 11s - loss: 0.6666 - acc: 0.7853 - val_loss: 0.7352 - val_acc: 0.7647
Epoch 162/200
 - 11s - loss: 0.6609 - acc: 0.7869 - val_loss: 0.7380 - val_acc: 0.7666
Epoch 163/200
 - 11s - loss: 0.6629 - acc: 0.7885 - val_loss: 0.7888 - val_acc: 0.7612
Epoch 164/200
 - 11s - loss: 0.6577 - acc: 0.7900 - val_loss: 0.7326 - val_acc: 0.7671
Epoch 165/200
 - 11s - loss: 0.6542 - acc: 0.7906 - val_loss: 0.7720 - val_acc: 0.7664
Epoch 166/200
 - 11s - loss: 0.6514 - acc: 0.7932 - val_loss: 0.7883 - val_acc: 0.7659
Epoch 167/200
 - 11s - loss: 0.6496 - acc: 0.7956 - val_loss: 0.7599 - val_acc: 0.7700
Epoch 168/200
 - 11s - loss: 0.6483 - acc: 0.7994 - val_loss: 0.7244 - val_acc: 0.7757
Epoch 169/200
 - 11s - loss: 0.6452 - acc: 0.8012 - val_loss: 0.7431 - val_acc: 0.7762
Epoch 170/200
 - 11s - loss: 0.6447 - acc: 0.8023 - val_loss: 0.7268 - val_acc: 0.7707
Epoch 171/200
 - 11s - loss: 0.6486 - acc: 0.8011 - val_loss: 0.7737 - val_acc: 0.7598
Epoch 172/200
 - 11s - loss: 0.6849 - acc: 0.7905 - val_loss: 0.8609 - val_acc: 0.7730
Epoch 173/200
 - 11s - loss: 0.6678 - acc: 0.8030 - val_loss: 0.7248 - val_acc: 0.7876
Epoch 174/200
 - 11s - loss: 0.6564 - acc: 0.8015 - val_loss: 1.3239 - val_acc: 0.7434
Epoch 175/200
 - 11s - loss: 0.7350 - acc: 0.7785 - val_loss: 0.8183 - val_acc: 0.7740
Epoch 176/200
 - 11s - loss: 0.6895 - acc: 0.7909 - val_loss: 0.7465 - val_acc: 0.7846
Epoch 177/200
 - 11s - loss: 0.6639 - acc: 0.8018 - val_loss: 0.7171 - val_acc: 0.7954
Epoch 178/200
 - 11s - loss: 0.6541 - acc: 0.8051 - val_loss: 0.6847 - val_acc: 0.8008
Epoch 179/200
 - 11s - loss: 0.6570 - acc: 0.8050 - val_loss: 0.7182 - val_acc: 0.8003
Epoch 180/200
 - 11s - loss: 0.6530 - acc: 0.8069 - val_loss: 0.7223 - val_acc: 0.7928
Epoch 181/200
 - 11s - loss: 0.6397 - acc: 0.8121 - val_loss: 0.7610 - val_acc: 0.7835
Epoch 182/200
 - 11s - loss: 0.6338 - acc: 0.8154 - val_loss: 0.7146 - val_acc: 0.7912
Epoch 183/200
 - 11s - loss: 0.6253 - acc: 0.8188 - val_loss: 0.7267 - val_acc: 0.7905
Epoch 184/200
 - 11s - loss: 0.6212 - acc: 0.8217 - val_loss: 0.7346 - val_acc: 0.7887
Epoch 185/200
 - 11s - loss: 0.6209 - acc: 0.8217 - val_loss: 0.7163 - val_acc: 0.7990
Epoch 186/200
 - 11s - loss: 0.6226 - acc: 0.8217 - val_loss: 0.6954 - val_acc: 0.8037
Epoch 187/200
 - 11s - loss: 0.6176 - acc: 0.8246 - val_loss: 0.6942 - val_acc: 0.8048
Epoch 188/200
 - 11s - loss: 0.6190 - acc: 0.8233 - val_loss: 0.6731 - val_acc: 0.8079
Epoch 189/200
 - 11s - loss: 0.6122 - acc: 0.8248 - val_loss: 0.7190 - val_acc: 0.7974
Epoch 190/200
 - 11s - loss: 0.6138 - acc: 0.8241 - val_loss: 0.6870 - val_acc: 0.8058
Epoch 191/200
 - 11s - loss: 0.6071 - acc: 0.8278 - val_loss: 0.7490 - val_acc: 0.7995
Epoch 192/200
 - 11s - loss: 0.6148 - acc: 0.8244 - val_loss: 0.6770 - val_acc: 0.8078
Epoch 193/200
 - 11s - loss: 0.6049 - acc: 0.8277 - val_loss: 0.6645 - val_acc: 0.8105
Epoch 194/200
 - 11s - loss: 0.5984 - acc: 0.8300 - val_loss: 0.6664 - val_acc: 0.8112
Epoch 195/200
 - 11s - loss: 0.5991 - acc: 0.8290 - val_loss: 0.6680 - val_acc: 0.8105
Epoch 196/200
 - 11s - loss: 0.6069 - acc: 0.8270 - val_loss: 0.6787 - val_acc: 0.8093
Epoch 197/200
 - 11s - loss: 0.6003 - acc: 0.8291 - val_loss: 0.6543 - val_acc: 0.8112
Epoch 198/200
 - 11s - loss: 0.5939 - acc: 0.8309 - val_loss: 0.6513 - val_acc: 0.8137
Epoch 199/200
 - 11s - loss: 0.5911 - acc: 0.8324 - val_loss: 0.6891 - val_acc: 0.8071
Epoch 200/200
 - 11s - loss: 0.5897 - acc: 0.8326 - val_loss: 0.6511 - val_acc: 0.8150
Using TensorFlow backend.


Elapsed time for Keras training (s):  2166.602009



End of UNET training

 
##################################################################################
Step2b: MAKING PREDICTIONS
##################################################################################
 
2020-03-05 11:48:38.549901: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:48:38.640616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:48:38.640634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:48:39.147176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:48:39.147194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:48:39.147198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:48:39.147812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20768 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
UNET MODEL =  1


validation data (X) (Y) shapes: (56, 224, 224, 3) (56, 224, 224, 12)
testing    data (X) (Y) shapes (101, 224, 224, 3) (101, 224, 224, 12)



now computing IoU over testing data set:
class ( 0)          Sky: #TP= 432554, #FP=  15871, #FN=  23419, IoU=0.917
class ( 1)         Wall: #TP=1133136, #FP= 225970, #FN= 170810, IoU=0.741
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1416998, #FP=  30484, #FN=  58021, IoU=0.941
class ( 4)     Sidewalk: #TP= 412708, #FP=  75872, #FN=  35725, IoU=0.787
class ( 5)   Vegetation: #TP= 809684, #FP= 245144, #FN=  16861, IoU=0.756
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=  19651, #FP=  33041, #FN= 136752, IoU=0.104
class ( 8)      vehicle: #TP=  70492, #FP=  14104, #FN=  23568, IoU=0.652
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=  15024, #FP= 117043, #FN=  54724, IoU=0.080
_________________
Mean IoU: 0.415

now computing IoU over validation data set:
class ( 0)          Sky: #TP= 421309, #FP=  17926, #FN=  48197, IoU=0.864
class ( 1)         Wall: #TP= 560117, #FP= 147417, #FN=  75045, IoU=0.716
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  32725, IoU=0.000
class ( 3)         Road: #TP= 857412, #FP=  22672, #FN=  39039, IoU=0.933
class ( 4)     Sidewalk: #TP=  90681, #FP=  27744, #FN=  34761, IoU=0.592
class ( 5)   Vegetation: #TP= 230390, #FP= 158743, #FN=  29410, IoU=0.550
class ( 6)         Sign: #TP=      1, #FP=      0, #FN=  42176, IoU=0.000
class ( 7)        Fence: #TP=   9416, #FP=   3549, #FN=  41992, IoU=0.171
class ( 8)      vehicle: #TP= 127797, #FP=  15735, #FN=  45083, IoU=0.678
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  16892, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN=  17085, IoU=0.000
class (11)  miscellanea: #TP=  44175, #FP=  74772, #FN=  46153, IoU=0.268
_________________
Mean IoU: 0.398
2020-03-05 11:48:56.790913: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:48:56.880830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:48:56.880849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:48:57.398445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:48:57.398466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:48:57.398470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:48:57.399102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20768 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
UNET MODEL =  2


validation data (X) (Y) shapes: (56, 224, 224, 3) (56, 224, 224, 12)
testing    data (X) (Y) shapes (101, 224, 224, 3) (101, 224, 224, 12)



now computing IoU over testing data set:
class ( 0)          Sky: #TP= 447885, #FP=  35466, #FN=   8088, IoU=0.911
class ( 1)         Wall: #TP=1154524, #FP= 305309, #FN= 149422, IoU=0.717
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1410551, #FP=  29879, #FN=  64468, IoU=0.937
class ( 4)     Sidewalk: #TP= 399667, #FP=  69154, #FN=  48766, IoU=0.772
class ( 5)   Vegetation: #TP= 784906, #FP= 139791, #FN=  41639, IoU=0.812
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=      0, #FP=      0, #FN= 156403, IoU=0.000
class ( 8)      vehicle: #TP=  77893, #FP=  47006, #FN=  16167, IoU=0.552
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=  31314, #FP= 134431, #FN=  38434, IoU=0.153
_________________
Mean IoU: 0.405

now computing IoU over validation data set:
class ( 0)          Sky: #TP= 453708, #FP=  37638, #FN=  15798, IoU=0.895
class ( 1)         Wall: #TP= 567433, #FP= 116857, #FN=  67729, IoU=0.755
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  32725, IoU=0.000
class ( 3)         Road: #TP= 860041, #FP=  23602, #FN=  36410, IoU=0.935
class ( 4)     Sidewalk: #TP=  91216, #FP=  30939, #FN=  34226, IoU=0.583
class ( 5)   Vegetation: #TP= 235187, #FP= 131635, #FN=  24613, IoU=0.601
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  42177, IoU=0.000
class ( 7)        Fence: #TP=      0, #FP=      0, #FN=  51408, IoU=0.000
class ( 8)      vehicle: #TP= 138149, #FP=  24036, #FN=  34731, IoU=0.702
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  16892, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN=  17085, IoU=0.000
class (11)  miscellanea: #TP=  39251, #FP=  60164, #FN=  51077, IoU=0.261
_________________
Mean IoU: 0.394
2020-03-05 11:49:15.380719: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:49:15.471252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:49:15.471271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:49:15.988157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:49:15.988175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:49:15.988179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:49:15.988777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20768 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
UNET MODEL =  3


validation data (X) (Y) shapes: (56, 224, 224, 3) (56, 224, 224, 12)
testing    data (X) (Y) shapes (101, 224, 224, 3) (101, 224, 224, 12)



now computing IoU over testing data set:
class ( 0)          Sky: #TP= 451592, #FP=  38134, #FN=   4381, IoU=0.914
class ( 1)         Wall: #TP=1140486, #FP= 395894, #FN= 163460, IoU=0.671
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1433777, #FP=  91551, #FN=  41242, IoU=0.915
class ( 4)     Sidewalk: #TP= 366091, #FP=  79676, #FN=  82342, IoU=0.693
class ( 5)   Vegetation: #TP= 680894, #FP= 192731, #FN= 145651, IoU=0.668
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=      0, #FP=      0, #FN= 156403, IoU=0.000
class ( 8)      vehicle: #TP=  79808, #FP= 115572, #FN=  14252, IoU=0.381
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=    326, #FP=   1244, #FN=  69422, IoU=0.005
_________________
Mean IoU: 0.354

now computing IoU over validation data set:
class ( 0)          Sky: #TP= 451415, #FP=  36871, #FN=  18091, IoU=0.891
class ( 1)         Wall: #TP= 562205, #FP= 152781, #FN=  72957, IoU=0.714
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  32725, IoU=0.000
class ( 3)         Road: #TP= 866481, #FP=  47809, #FN=  29970, IoU=0.918
class ( 4)     Sidewalk: #TP=  72221, #FP=  37681, #FN=  53221, IoU=0.443
class ( 5)   Vegetation: #TP= 207740, #FP= 173495, #FN=  52060, IoU=0.479
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  42177, IoU=0.000
class ( 7)        Fence: #TP=      0, #FP=      0, #FN=  51408, IoU=0.000
class ( 8)      vehicle: #TP= 129308, #FP=  70692, #FN=  43572, IoU=0.531
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  16892, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN=  17085, IoU=0.000
class (11)  miscellanea: #TP=    595, #FP=    562, #FN=  89733, IoU=0.007
_________________
Mean IoU: 0.332
 
#######################################################################################
Step3: KERAS to TENSORFLOW GRAPH CONVERSION
#######################################################################################
 
2020-03-05 11:49:33.314218: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:49:33.405120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:49:33.405140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:49:33.927143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:49:33.927163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:49:33.927167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:49:33.927784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
model name =  unet1

 TF input node name:
[<tf.Tensor 'input_1:0' shape=(?, 224, 224, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'conv2d_19/Relu:0' shape=(?, 224, 224, 12) dtype=float32>]

FINISHED CREATING TF FILES

2020-03-05 11:49:40.716750: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:49:40.806968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:49:40.807000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:49:41.327295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:49:41.327315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:49:41.327318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:49:41.327928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
model name =  unet2

 TF input node name:
[<tf.Tensor 'input_1:0' shape=(?, 224, 224, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'conv2d_23/Relu:0' shape=(?, 224, 224, 12) dtype=float32>]

FINISHED CREATING TF FILES

2020-03-05 11:49:48.312272: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:49:48.395950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:49:48.395967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:49:48.919376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:49:48.919397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:49:48.919400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:49:48.920007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
model name =  unet3

 TF input node name:
[<tf.Tensor 'input_1:0' shape=(?, 224, 224, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'conv2d_19/Relu:0' shape=(?, 224, 224, 12) dtype=float32>]

FINISHED CREATING TF FILES

 
##############################################################################
Step4a: FREEZE TF GRAPHS
##############################################################################
 
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:249: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
2020-03-05 11:50:00.078527: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:50:00.167345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:50:00.167364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:50:00.687406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:50:00.687428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:50:00.687432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:50:00.688051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:249: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
2020-03-05 11:50:07.922401: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:50:08.008987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:50:08.009006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:50:08.530553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:50:08.530577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:50:08.530580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:50:08.531199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:249: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
2020-03-05 11:50:15.680400: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:50:15.767898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:50:15.767916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:50:16.288339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:50:16.288361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:50:16.288364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:50:16.288976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
 
##############################################################################
Step4a: INSPECT FROZEN GRAPH
##############################################################################
 
Op types used: 130 Const, 119 Identity, 19 BiasAdd, 19 Conv2D, 19 Relu, 18 FusedBatchNorm, 4 ConcatV2, 4 MaxPool, 4 Mul, 4 ResizeBilinear, 4 Shape, 4 StridedSlice, 1 Placeholder

Found 1 possible inputs: (name=input_1, type=float(1), shape=[?,224,224,3]) 
Found 1 possible outputs: (name=conv2d_19/Relu, op=Relu) 
Op types used: 138 Const, 127 Identity, 23 BiasAdd, 23 Conv2D, 23 Relu, 18 FusedBatchNorm, 4 ConcatV2, 4 MaxPool, 4 Mul, 4 ResizeBilinear, 4 Shape, 4 StridedSlice, 1 Placeholder

Found 1 possible inputs: (name=input_1, type=float(1), shape=[?,224,224,3]) 
Found 1 possible outputs: (name=conv2d_23/Relu, op=Relu) 
Op types used: 170 Const, 127 Identity, 23 BiasAdd, 19 Conv2D, 19 Relu, 18 FusedBatchNorm, 12 StridedSlice, 8 Mul, 4 ConcatV2, 4 Conv2DBackpropInput, 4 MaxPool, 4 Pack, 4 Shape, 1 Placeholder

Found 1 possible inputs: (name=input_1, type=float(1), shape=[?,224,224,3]) 
Found 1 possible outputs: (name=conv2d_19/Relu, op=Relu) 
 
##############################################################################
Step4b: EVALUATING THE ORIGINAL GRAPH
##############################################################################
 
2020-03-05 11:50:38.575034: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:50:38.657904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:50:38.657923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:50:39.169175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:50:39.169196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:50:39.169200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:50:39.169830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
X tensor shape:  (101, 224, 224, 3)  Y tensor shape:  (101, 224, 224, 12)
(101, 224, 224) (101, 224, 224)
class ( 0)          Sky: #TP= 432554, #FP=  15871, #FN=  23419, IoU=0.917
class ( 1)         Wall: #TP=1133136, #FP= 225970, #FN= 170810, IoU=0.741
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1416998, #FP=  30484, #FN=  58021, IoU=0.941
class ( 4)     Sidewalk: #TP= 412708, #FP=  75872, #FN=  35725, IoU=0.787
class ( 5)   Vegetation: #TP= 809684, #FP= 245144, #FN=  16861, IoU=0.756
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=  19651, #FP=  33041, #FN= 136752, IoU=0.104
class ( 8)      vehicle: #TP=  70492, #FP=  14105, #FN=  23568, IoU=0.652
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=  15024, #FP= 117042, #FN=  54724, IoU=0.080
_________________
Mean IoU: 0.415
FINISHED!
2020-03-05 11:50:53.130909: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:50:53.212347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:50:53.212366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:50:53.719503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:50:53.719523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:50:53.719527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:50:53.720174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
X tensor shape:  (101, 224, 224, 3)  Y tensor shape:  (101, 224, 224, 12)
(101, 224, 224) (101, 224, 224)
class ( 0)          Sky: #TP= 447885, #FP=  35466, #FN=   8088, IoU=0.911
class ( 1)         Wall: #TP=1154524, #FP= 305309, #FN= 149422, IoU=0.717
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1410551, #FP=  29879, #FN=  64468, IoU=0.937
class ( 4)     Sidewalk: #TP= 399667, #FP=  69154, #FN=  48766, IoU=0.772
class ( 5)   Vegetation: #TP= 784906, #FP= 139791, #FN=  41639, IoU=0.812
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=      0, #FP=      0, #FN= 156403, IoU=0.000
class ( 8)      vehicle: #TP=  77893, #FP=  47006, #FN=  16167, IoU=0.552
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=  31314, #FP= 134431, #FN=  38434, IoU=0.153
_________________
Mean IoU: 0.405
FINISHED!
2020-03-05 11:51:07.992971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:51:08.082261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:51:08.082280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:51:08.612933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:51:08.612954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:51:08.612958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:51:08.613554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
X tensor shape:  (101, 224, 224, 3)  Y tensor shape:  (101, 224, 224, 12)
(101, 224, 224) (101, 224, 224)
class ( 0)          Sky: #TP= 451592, #FP=  38134, #FN=   4381, IoU=0.914
class ( 1)         Wall: #TP=1140486, #FP= 395893, #FN= 163460, IoU=0.671
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1433777, #FP=  91551, #FN=  41242, IoU=0.915
class ( 4)     Sidewalk: #TP= 366091, #FP=  79676, #FN=  82342, IoU=0.693
class ( 5)   Vegetation: #TP= 680895, #FP= 192731, #FN= 145650, IoU=0.668
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=      0, #FP=      0, #FN= 156403, IoU=0.000
class ( 8)      vehicle: #TP=  79808, #FP= 115572, #FN=  14252, IoU=0.381
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=    326, #FP=   1244, #FN=  69422, IoU=0.005
_________________
Mean IoU: 0.354
FINISHED!
 
##########################################################################
Step5a: QUANTIZATION
##########################################################################
 
 
bash: decent_q: command not found
 
Using TensorFlow backend.
                                                                               N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--                                                                                10% (1 of 10) |##                       | Elapsed Time: 0:00:03 ETA:   0:00:32                                                                                20% (2 of 10) |#####                    | Elapsed Time: 0:00:07 ETA:   0:00:27                                                                                30% (3 of 10) |#######                  | Elapsed Time: 0:00:10 ETA:   0:00:23                                                                                40% (4 of 10) |##########               | Elapsed Time: 0:00:13 ETA:   0:00:20                                                                                50% (5 of 10) |############             | Elapsed Time: 0:00:17 ETA:   0:00:16                                                                                60% (6 of 10) |###############          | Elapsed Time: 0:00:20 ETA:   0:00:13                                                                                70% (7 of 10) |#################        | Elapsed Time: 0:00:23 ETA:   0:00:10                                                                                80% (8 of 10) |####################     | Elapsed Time: 0:00:27 ETA:   0:00:06                                                                                90% (9 of 10) |######################   | Elapsed Time: 0:00:30 ETA:   0:00:03                                                                               100% (10 of 10) |########################| Elapsed Time: 0:00:33 Time:  0:00:33
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
script running on folder  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
CALIB DIR  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code/../workspace/dataset1/img_calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 10 iterations...
INFO: Calibration Done.
INFO: Generating Deploy Model...
INFO: Deploy Model Generated.
********************* Quantization Summary *********************      
INFO: Output:       
  quantize_eval_model: .././workspace/quantize_results/unet1/quantize_eval_model.pb       
  deploy_model: .././workspace/quantize_results/unet1/deploy_model.pb
Using TensorFlow backend.
                                                                               N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--                                                                                10% (1 of 10) |##                       | Elapsed Time: 0:00:03 ETA:   0:00:32                                                                                20% (2 of 10) |#####                    | Elapsed Time: 0:00:06 ETA:   0:00:27                                                                                30% (3 of 10) |#######                  | Elapsed Time: 0:00:10 ETA:   0:00:23                                                                                40% (4 of 10) |##########               | Elapsed Time: 0:00:13 ETA:   0:00:20                                                                                50% (5 of 10) |############             | Elapsed Time: 0:00:17 ETA:   0:00:17                                                                                60% (6 of 10) |###############          | Elapsed Time: 0:00:20 ETA:   0:00:13                                                                                70% (7 of 10) |#################        | Elapsed Time: 0:00:23 ETA:   0:00:10                                                                                80% (8 of 10) |####################     | Elapsed Time: 0:00:27 ETA:   0:00:06                                                                                90% (9 of 10) |######################   | Elapsed Time: 0:00:30 ETA:   0:00:03                                                                               100% (10 of 10) |########################| Elapsed Time: 0:00:34 Time:  0:00:34
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
script running on folder  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
CALIB DIR  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code/../workspace/dataset1/img_calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 10 iterations...
INFO: Calibration Done.
INFO: Generating Deploy Model...
INFO: Deploy Model Generated.
********************* Quantization Summary *********************      
INFO: Output:       
  quantize_eval_model: .././workspace/quantize_results/unet2/quantize_eval_model.pb       
  deploy_model: .././workspace/quantize_results/unet2/deploy_model.pb
Using TensorFlow backend.
                                                                               N/A% (0 of 10) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--                                                                                10% (1 of 10) |##                       | Elapsed Time: 0:00:03 ETA:   0:00:32                                                                                20% (2 of 10) |#####                    | Elapsed Time: 0:00:06 ETA:   0:00:27                                                                                30% (3 of 10) |#######                  | Elapsed Time: 0:00:10 ETA:   0:00:23                                                                                40% (4 of 10) |##########               | Elapsed Time: 0:00:13 ETA:   0:00:20                                                                                50% (5 of 10) |############             | Elapsed Time: 0:00:17 ETA:   0:00:16                                                                                60% (6 of 10) |###############          | Elapsed Time: 0:00:20 ETA:   0:00:13                                                                                70% (7 of 10) |#################        | Elapsed Time: 0:00:23 ETA:   0:00:10                                                                                80% (8 of 10) |####################     | Elapsed Time: 0:00:27 ETA:   0:00:06                                                                                90% (9 of 10) |######################   | Elapsed Time: 0:00:30 ETA:   0:00:03                                                                               100% (10 of 10) |########################| Elapsed Time: 0:00:33 Time:  0:00:33
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
script running on folder  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
CALIB DIR  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code/../workspace/dataset1/img_calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 10 iterations...
INFO: Calibration Done.
INFO: Generating Deploy Model...
INFO: Deploy Model Generated.
********************* Quantization Summary *********************      
INFO: Output:       
  quantize_eval_model: .././workspace/quantize_results/unet3/quantize_eval_model.pb       
  deploy_model: .././workspace/quantize_results/unet3/deploy_model.pb
 
##############################################################################
Step5b: EVALUATE QUANTIZED GRAPH
##############################################################################
 
2020-03-05 11:53:35.699608: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:53:35.785655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:53:35.785675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:53:36.299727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:53:36.299748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:53:36.299752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:53:36.300370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
X tensor shape:  (101, 224, 224, 3)  Y tensor shape:  (101, 224, 224, 12)
(101, 224, 224) (101, 224, 224)
class ( 0)          Sky: #TP= 429370, #FP=  14884, #FN=  26603, IoU=0.912
class ( 1)         Wall: #TP=1104919, #FP= 223487, #FN= 199027, IoU=0.723
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1417936, #FP=  32477, #FN=  57083, IoU=0.941
class ( 4)     Sidewalk: #TP= 412677, #FP=  77874, #FN=  35756, IoU=0.784
class ( 5)   Vegetation: #TP= 810489, #FP= 283132, #FN=  16056, IoU=0.730
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=  16211, #FP=  32163, #FN= 140192, IoU=0.086
class ( 8)      vehicle: #TP=  71278, #FP=  15396, #FN=  22782, IoU=0.651
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=  14093, #FP= 111390, #FN=  55655, IoU=0.078
_________________
Mean IoU: 0.409
FINISHED!
2020-03-05 11:53:54.594150: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:53:54.684315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:53:54.684333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:53:55.193693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:53:55.193714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:53:55.193718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:53:55.194397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
X tensor shape:  (101, 224, 224, 3)  Y tensor shape:  (101, 224, 224, 12)
(101, 224, 224) (101, 224, 224)
class ( 0)          Sky: #TP= 446649, #FP=  33016, #FN=   9324, IoU=0.913
class ( 1)         Wall: #TP=1134524, #FP= 297058, #FN= 169422, IoU=0.709
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1415149, #FP=  34537, #FN=  59870, IoU=0.937
class ( 4)     Sidewalk: #TP= 397551, #FP=  67532, #FN=  50882, IoU=0.770
class ( 5)   Vegetation: #TP= 787343, #FP= 160969, #FN=  39202, IoU=0.797
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=      0, #FP=      0, #FN= 156403, IoU=0.000
class ( 8)      vehicle: #TP=  77920, #FP=  47188, #FN=  16140, IoU=0.552
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=  31569, #FP= 136771, #FN=  38179, IoU=0.153
_________________
Mean IoU: 0.403
FINISHED!
2020-03-05 11:54:13.703066: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-03-05 11:54:13.786576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
totalMemory: 23.86GiB freeMemory: 22.97GiB
2020-03-05 11:54:13.786594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-03-05 11:54:14.299563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-05 11:54:14.299585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-03-05 11:54:14.299589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-03-05 11:54:14.300185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
Using TensorFlow backend.
fcn_config.py runs from  /workspace/tutorials/VAI-KERAS-FCN8-SEMSEG/files/code
X tensor shape:  (101, 224, 224, 3)  Y tensor shape:  (101, 224, 224, 12)
(101, 224, 224) (101, 224, 224)
class ( 0)          Sky: #TP= 429370, #FP=  14884, #FN=  26603, IoU=0.912
class ( 1)         Wall: #TP=1104919, #FP= 223487, #FN= 199027, IoU=0.723
class ( 2)         Pole: #TP=      0, #FP=      0, #FN=  36420, IoU=0.000
class ( 3)         Road: #TP=1417936, #FP=  32477, #FN=  57083, IoU=0.941
class ( 4)     Sidewalk: #TP= 412677, #FP=  77874, #FN=  35756, IoU=0.784
class ( 5)   Vegetation: #TP= 810489, #FP= 283132, #FN=  16056, IoU=0.730
class ( 6)         Sign: #TP=      0, #FP=      0, #FN=  53392, IoU=0.000
class ( 7)        Fence: #TP=  16211, #FP=  32163, #FN= 140192, IoU=0.086
class ( 8)      vehicle: #TP=  71278, #FP=  15396, #FN=  22782, IoU=0.651
class ( 9)   Pedestrian: #TP=      0, #FP=      0, #FN=  36865, IoU=0.000
class (10)    Bicyclist: #TP=      0, #FP=      0, #FN= 110972, IoU=0.000
class (11)  miscellanea: #TP=  14093, #FP= 111390, #FN=  55655, IoU=0.078
_________________
Mean IoU: 0.409
FINISHED!
 
##########################################################################
COMPILE UNET ELF FILE WITH Vitis AI
##########################################################################
 

Kernel topology "unet1_kernel_graph.jpg" for network "unet1"
kernel list info for network "unet1"
                               Kernel ID : Name
                                       0 : unet1

                             Kernel Name : unet1
--------------------------------------------------------------------------------
                             Kernel Type : DPUKernel
                               Code Size : 0.49MB
                              Param Size : 29.93MB
                           Workload MACs : 85952.70MOPS
                         IO Memory Space : 18.18MB
                              Mean Value : 0, 0, 0, 
                      Total Tensor Count : 32
                Boundary Input Tensor(s)   (H*W*C)
                            input_1:0(0) : 224*224*3

               Boundary Output Tensor(s)   (H*W*C)
                     conv2d_19_Relu:0(0) : 224*224*12

                        Total Node Count : 27
                           Input Node(s)   (H*W*C)
                 conv2d_1_convolution(0) : 224*224*3

                          Output Node(s)   (H*W*C)
                conv2d_19_convolution(0) : 224*224*12




**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
/opt/vitis_ai/compiler/arch/dpuv2/ZCU102/ZCU102.json

Kernel topology "unet2_kernel_graph.jpg" for network "unet2"
kernel list info for network "unet2"
                               Kernel ID : Name
                                       0 : unet2

                             Kernel Name : unet2
--------------------------------------------------------------------------------
                             Kernel Type : DPUKernel
                               Code Size : 0.49MB
                              Param Size : 29.60MB
                           Workload MACs : 84308.52MOPS
                         IO Memory Space : 15.48MB
                              Mean Value : 0, 0, 0, 
                      Total Tensor Count : 36
                Boundary Input Tensor(s)   (H*W*C)
                            input_1:0(0) : 224*224*3

               Boundary Output Tensor(s)   (H*W*C)
                     conv2d_23_Relu:0(0) : 224*224*12

                        Total Node Count : 31
                           Input Node(s)   (H*W*C)
                 conv2d_1_convolution(0) : 224*224*3

                          Output Node(s)   (H*W*C)
                conv2d_23_convolution(0) : 224*224*12




**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
/opt/vitis_ai/compiler/arch/dpuv2/ZCU102/ZCU102.json

Kernel topology "unet3_kernel_graph.jpg" for network "unet3"
kernel list info for network "unet3"
                               Kernel ID : Name
                                       0 : unet3

                             Kernel Name : unet3
--------------------------------------------------------------------------------
                             Kernel Type : DPUKernel
                               Code Size : 0.49MB
                              Param Size : 29.93MB
                           Workload MACs : 85952.70MOPS
                         IO Memory Space : 18.18MB
                              Mean Value : 0, 0, 0, 
                      Total Tensor Count : 32
                Boundary Input Tensor(s)   (H*W*C)
                            input_1:0(0) : 224*224*3

               Boundary Output Tensor(s)   (H*W*C)
                     conv2d_19_Relu:0(0) : 224*224*12

                        Total Node Count : 27
                           Input Node(s)   (H*W*C)
                 conv2d_1_convolution(0) : 224*224*3

                          Output Node(s)   (H*W*C)
                conv2d_19_convolution(0) : 224*224*12




**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************
/opt/vitis_ai/compiler/arch/dpuv2/ZCU102/ZCU102.json
